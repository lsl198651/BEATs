[2023-07-26 17:31:10 - INFO:] # batch_size = 64
[2023-07-26 17:31:10 - INFO:] # learning_rate = 0.005
[2023-07-26 17:31:10 - INFO:] # num_epochs = 500
[2023-07-26 17:31:10 - INFO:] # padding_size = 3500
[2023-07-26 17:31:10 - INFO:] # criterion = CrossEntropyLoss()
[2023-07-26 17:31:10 - INFO:] # optimizer = AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.98)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.005
    maximize: False
    weight_decay: 0.01
)
[2023-07-26 17:31:10 - INFO:] -------------------------------
[2023-07-26 17:31:48 - INFO:] epoch: 1/500
[2023-07-26 17:31:48 - INFO:] learning_rate: 0.0050
[2023-07-26 17:31:48 - INFO:] train_acc: 70.0059%, train_loss: 0.0092
[2023-07-26 17:31:48 - INFO:] test_acc: 72.3659%, test_loss: 0.0088
[2023-07-26 17:31:48 - INFO:] max_train_acc: 70.0059%
[2023-07-26 17:31:48 - INFO:] max_test_acc: 72.3659%
[2023-07-26 17:31:48 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:31:48 - INFO:] ======================================
[2023-07-26 17:32:20 - INFO:] epoch: 2/500
[2023-07-26 17:32:20 - INFO:] learning_rate: 0.0050
[2023-07-26 17:32:20 - INFO:] train_acc: 72.2869%, train_loss: 0.0089
[2023-07-26 17:32:20 - INFO:] test_acc: 77.2927%, test_loss: 0.0083
[2023-07-26 17:32:20 - INFO:] max_train_acc: 72.2869%
[2023-07-26 17:32:20 - INFO:] max_test_acc: 77.2927%
[2023-07-26 17:32:20 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:32:20 - INFO:] ======================================
[2023-07-26 17:32:54 - INFO:] epoch: 3/500
[2023-07-26 17:32:54 - INFO:] learning_rate: 0.0050
[2023-07-26 17:32:54 - INFO:] train_acc: 73.3804%, train_loss: 0.0088
[2023-07-26 17:32:54 - INFO:] test_acc: 77.8293%, test_loss: 0.0081
[2023-07-26 17:32:54 - INFO:] max_train_acc: 73.3804%
[2023-07-26 17:32:54 - INFO:] max_test_acc: 77.8293%
[2023-07-26 17:32:54 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:32:54 - INFO:] ======================================
[2023-07-26 17:33:27 - INFO:] epoch: 4/500
[2023-07-26 17:33:27 - INFO:] learning_rate: 0.0050
[2023-07-26 17:33:27 - INFO:] train_acc: 73.5391%, train_loss: 0.0087
[2023-07-26 17:33:27 - INFO:] test_acc: 78.1707%, test_loss: 0.0081
[2023-07-26 17:33:27 - INFO:] max_train_acc: 73.5391%
[2023-07-26 17:33:27 - INFO:] max_test_acc: 78.1707%
[2023-07-26 17:33:27 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:33:27 - INFO:] ======================================
[2023-07-26 17:34:00 - INFO:] epoch: 5/500
[2023-07-26 17:34:00 - INFO:] learning_rate: 0.0050
[2023-07-26 17:34:00 - INFO:] train_acc: 73.7331%, train_loss: 0.0087
[2023-07-26 17:34:00 - INFO:] test_acc: 77.7561%, test_loss: 0.0081
[2023-07-26 17:34:00 - INFO:] max_train_acc: 73.7331%
[2023-07-26 17:34:00 - INFO:] max_test_acc: 78.1707%
[2023-07-26 17:34:00 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:34:00 - INFO:] ======================================
[2023-07-26 17:34:33 - INFO:] epoch: 6/500
[2023-07-26 17:34:33 - INFO:] learning_rate: 0.0050
[2023-07-26 17:34:33 - INFO:] train_acc: 73.9271%, train_loss: 0.0086
[2023-07-26 17:34:33 - INFO:] test_acc: 76.6585%, test_loss: 0.0083
[2023-07-26 17:34:33 - INFO:] max_train_acc: 73.9271%
[2023-07-26 17:34:33 - INFO:] max_test_acc: 78.1707%
[2023-07-26 17:34:33 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:34:33 - INFO:] ======================================
[2023-07-26 17:35:05 - INFO:] epoch: 7/500
[2023-07-26 17:35:05 - INFO:] learning_rate: 0.0050
[2023-07-26 17:35:05 - INFO:] train_acc: 73.9506%, train_loss: 0.0086
[2023-07-26 17:35:05 - INFO:] test_acc: 78.2683%, test_loss: 0.0080
[2023-07-26 17:35:05 - INFO:] max_train_acc: 73.9506%
[2023-07-26 17:35:05 - INFO:] max_test_acc: 78.2683%
[2023-07-26 17:35:05 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:35:05 - INFO:] ======================================
[2023-07-26 17:35:38 - INFO:] epoch: 8/500
[2023-07-26 17:35:38 - INFO:] learning_rate: 0.0050
[2023-07-26 17:35:38 - INFO:] train_acc: 74.1858%, train_loss: 0.0086
[2023-07-26 17:35:38 - INFO:] test_acc: 78.2927%, test_loss: 0.0080
[2023-07-26 17:35:38 - INFO:] max_train_acc: 74.1858%
[2023-07-26 17:35:38 - INFO:] max_test_acc: 78.2927%
[2023-07-26 17:35:38 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:35:38 - INFO:] ======================================
[2023-07-26 17:36:11 - INFO:] epoch: 9/500
[2023-07-26 17:36:11 - INFO:] learning_rate: 0.0050
[2023-07-26 17:36:11 - INFO:] train_acc: 74.8031%, train_loss: 0.0086
[2023-07-26 17:36:11 - INFO:] test_acc: 78.1463%, test_loss: 0.0080
[2023-07-26 17:36:11 - INFO:] max_train_acc: 74.8031%
[2023-07-26 17:36:11 - INFO:] max_test_acc: 78.2927%
[2023-07-26 17:36:11 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:36:11 - INFO:] ======================================
[2023-07-26 17:36:44 - INFO:] epoch: 10/500
[2023-07-26 17:36:44 - INFO:] learning_rate: 0.0050
[2023-07-26 17:36:44 - INFO:] train_acc: 74.0858%, train_loss: 0.0086
[2023-07-26 17:36:44 - INFO:] test_acc: 78.7073%, test_loss: 0.0079
[2023-07-26 17:36:44 - INFO:] max_train_acc: 74.8031%
[2023-07-26 17:36:44 - INFO:] max_test_acc: 78.7073%
[2023-07-26 17:36:44 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:36:44 - INFO:] ======================================
[2023-07-26 17:37:17 - INFO:] epoch: 11/500
[2023-07-26 17:37:17 - INFO:] learning_rate: 0.0050
[2023-07-26 17:37:17 - INFO:] train_acc: 74.0800%, train_loss: 0.0086
[2023-07-26 17:37:17 - INFO:] test_acc: 78.4146%, test_loss: 0.0080
[2023-07-26 17:37:17 - INFO:] max_train_acc: 74.8031%
[2023-07-26 17:37:17 - INFO:] max_test_acc: 78.7073%
[2023-07-26 17:37:17 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:37:17 - INFO:] ======================================
[2023-07-26 17:37:49 - INFO:] epoch: 12/500
[2023-07-26 17:37:49 - INFO:] learning_rate: 0.0050
[2023-07-26 17:37:49 - INFO:] train_acc: 74.0153%, train_loss: 0.0086
[2023-07-26 17:37:49 - INFO:] test_acc: 78.6098%, test_loss: 0.0080
[2023-07-26 17:37:49 - INFO:] max_train_acc: 74.8031%
[2023-07-26 17:37:49 - INFO:] max_test_acc: 78.7073%
[2023-07-26 17:37:49 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:37:49 - INFO:] ======================================
[2023-07-26 17:38:22 - INFO:] epoch: 13/500
[2023-07-26 17:38:22 - INFO:] learning_rate: 0.0050
[2023-07-26 17:38:22 - INFO:] train_acc: 74.4150%, train_loss: 0.0086
[2023-07-26 17:38:22 - INFO:] test_acc: 78.4146%, test_loss: 0.0079
[2023-07-26 17:38:22 - INFO:] max_train_acc: 74.8031%
[2023-07-26 17:38:22 - INFO:] max_test_acc: 78.7073%
[2023-07-26 17:38:22 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:38:22 - INFO:] ======================================
[2023-07-26 17:38:55 - INFO:] epoch: 14/500
[2023-07-26 17:38:55 - INFO:] learning_rate: 0.0050
[2023-07-26 17:38:55 - INFO:] train_acc: 74.3798%, train_loss: 0.0086
[2023-07-26 17:38:55 - INFO:] test_acc: 78.0244%, test_loss: 0.0080
[2023-07-26 17:38:55 - INFO:] max_train_acc: 74.8031%
[2023-07-26 17:38:55 - INFO:] max_test_acc: 78.7073%
[2023-07-26 17:38:55 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:38:55 - INFO:] ======================================
[2023-07-26 17:39:27 - INFO:] epoch: 15/500
[2023-07-26 17:39:27 - INFO:] learning_rate: 0.0050
[2023-07-26 17:39:27 - INFO:] train_acc: 74.6384%, train_loss: 0.0086
[2023-07-26 17:39:27 - INFO:] test_acc: 77.7317%, test_loss: 0.0081
[2023-07-26 17:39:27 - INFO:] max_train_acc: 74.8031%
[2023-07-26 17:39:27 - INFO:] max_test_acc: 78.7073%
[2023-07-26 17:39:27 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:39:27 - INFO:] ======================================
[2023-07-26 17:40:00 - INFO:] epoch: 16/500
[2023-07-26 17:40:00 - INFO:] learning_rate: 0.0050
[2023-07-26 17:40:00 - INFO:] train_acc: 74.6326%, train_loss: 0.0086
[2023-07-26 17:40:00 - INFO:] test_acc: 78.3659%, test_loss: 0.0080
[2023-07-26 17:40:00 - INFO:] max_train_acc: 74.8031%
[2023-07-26 17:40:00 - INFO:] max_test_acc: 78.7073%
[2023-07-26 17:40:00 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:40:00 - INFO:] ======================================
[2023-07-26 17:40:33 - INFO:] epoch: 17/500
[2023-07-26 17:40:33 - INFO:] learning_rate: 0.0050
[2023-07-26 17:40:33 - INFO:] train_acc: 74.3857%, train_loss: 0.0086
[2023-07-26 17:40:33 - INFO:] test_acc: 78.2927%, test_loss: 0.0080
[2023-07-26 17:40:33 - INFO:] max_train_acc: 74.8031%
[2023-07-26 17:40:33 - INFO:] max_test_acc: 78.7073%
[2023-07-26 17:40:33 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:40:33 - INFO:] ======================================
[2023-07-26 17:41:06 - INFO:] epoch: 18/500
[2023-07-26 17:41:06 - INFO:] learning_rate: 0.0050
[2023-07-26 17:41:06 - INFO:] train_acc: 74.5561%, train_loss: 0.0085
[2023-07-26 17:41:06 - INFO:] test_acc: 78.4878%, test_loss: 0.0079
[2023-07-26 17:41:06 - INFO:] max_train_acc: 74.8031%
[2023-07-26 17:41:06 - INFO:] max_test_acc: 78.7073%
[2023-07-26 17:41:06 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:41:06 - INFO:] ======================================
[2023-07-26 17:41:38 - INFO:] epoch: 19/500
[2023-07-26 17:41:38 - INFO:] learning_rate: 0.0050
[2023-07-26 17:41:38 - INFO:] train_acc: 74.6620%, train_loss: 0.0085
[2023-07-26 17:41:38 - INFO:] test_acc: 78.4878%, test_loss: 0.0079
[2023-07-26 17:41:38 - INFO:] max_train_acc: 74.8031%
[2023-07-26 17:41:38 - INFO:] max_test_acc: 78.7073%
[2023-07-26 17:41:38 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:41:38 - INFO:] ======================================
[2023-07-26 17:42:11 - INFO:] epoch: 20/500
[2023-07-26 17:42:11 - INFO:] learning_rate: 0.0050
[2023-07-26 17:42:11 - INFO:] train_acc: 74.3621%, train_loss: 0.0085
[2023-07-26 17:42:11 - INFO:] test_acc: 78.6098%, test_loss: 0.0079
[2023-07-26 17:42:11 - INFO:] max_train_acc: 74.8031%
[2023-07-26 17:42:11 - INFO:] max_test_acc: 78.7073%
[2023-07-26 17:42:11 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:42:11 - INFO:] ======================================
[2023-07-26 17:42:44 - INFO:] epoch: 21/500
[2023-07-26 17:42:44 - INFO:] learning_rate: 0.0050
[2023-07-26 17:42:44 - INFO:] train_acc: 74.4503%, train_loss: 0.0085
[2023-07-26 17:42:44 - INFO:] test_acc: 78.5122%, test_loss: 0.0080
[2023-07-26 17:42:44 - INFO:] max_train_acc: 74.8031%
[2023-07-26 17:42:44 - INFO:] max_test_acc: 78.7073%
[2023-07-26 17:42:44 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:42:44 - INFO:] ======================================
[2023-07-26 17:43:17 - INFO:] epoch: 22/500
[2023-07-26 17:43:17 - INFO:] learning_rate: 0.0050
[2023-07-26 17:43:17 - INFO:] train_acc: 74.6855%, train_loss: 0.0085
[2023-07-26 17:43:17 - INFO:] test_acc: 78.6585%, test_loss: 0.0079
[2023-07-26 17:43:17 - INFO:] max_train_acc: 74.8031%
[2023-07-26 17:43:17 - INFO:] max_test_acc: 78.7073%
[2023-07-26 17:43:17 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:43:17 - INFO:] ======================================
[2023-07-26 17:43:50 - INFO:] epoch: 23/500
[2023-07-26 17:43:50 - INFO:] learning_rate: 0.0050
[2023-07-26 17:43:50 - INFO:] train_acc: 74.6561%, train_loss: 0.0085
[2023-07-26 17:43:50 - INFO:] test_acc: 78.4146%, test_loss: 0.0080
[2023-07-26 17:43:50 - INFO:] max_train_acc: 74.8031%
[2023-07-26 17:43:50 - INFO:] max_test_acc: 78.7073%
[2023-07-26 17:43:50 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:43:50 - INFO:] ======================================
[2023-07-26 17:44:23 - INFO:] epoch: 24/500
[2023-07-26 17:44:23 - INFO:] learning_rate: 0.0050
[2023-07-26 17:44:23 - INFO:] train_acc: 74.9148%, train_loss: 0.0085
[2023-07-26 17:44:23 - INFO:] test_acc: 78.3415%, test_loss: 0.0080
[2023-07-26 17:44:23 - INFO:] max_train_acc: 74.9148%
[2023-07-26 17:44:23 - INFO:] max_test_acc: 78.7073%
[2023-07-26 17:44:23 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:44:23 - INFO:] ======================================
[2023-07-26 17:44:56 - INFO:] epoch: 25/500
[2023-07-26 17:44:56 - INFO:] learning_rate: 0.0050
[2023-07-26 17:44:56 - INFO:] train_acc: 74.7031%, train_loss: 0.0085
[2023-07-26 17:44:56 - INFO:] test_acc: 78.4390%, test_loss: 0.0079
[2023-07-26 17:44:56 - INFO:] max_train_acc: 74.9148%
[2023-07-26 17:44:56 - INFO:] max_test_acc: 78.7073%
[2023-07-26 17:44:56 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:44:56 - INFO:] ======================================
[2023-07-26 17:45:29 - INFO:] epoch: 26/500
[2023-07-26 17:45:29 - INFO:] learning_rate: 0.0050
[2023-07-26 17:45:29 - INFO:] train_acc: 74.7031%, train_loss: 0.0085
[2023-07-26 17:45:29 - INFO:] test_acc: 78.2195%, test_loss: 0.0079
[2023-07-26 17:45:29 - INFO:] max_train_acc: 74.9148%
[2023-07-26 17:45:29 - INFO:] max_test_acc: 78.7073%
[2023-07-26 17:45:29 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:45:29 - INFO:] ======================================
[2023-07-26 17:46:03 - INFO:] epoch: 27/500
[2023-07-26 17:46:03 - INFO:] learning_rate: 0.0050
[2023-07-26 17:46:03 - INFO:] train_acc: 74.6091%, train_loss: 0.0085
[2023-07-26 17:46:03 - INFO:] test_acc: 78.3415%, test_loss: 0.0081
[2023-07-26 17:46:03 - INFO:] max_train_acc: 74.9148%
[2023-07-26 17:46:03 - INFO:] max_test_acc: 78.7073%
[2023-07-26 17:46:03 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:46:03 - INFO:] ======================================
[2023-07-26 17:46:36 - INFO:] epoch: 28/500
[2023-07-26 17:46:36 - INFO:] learning_rate: 0.0050
[2023-07-26 17:46:36 - INFO:] train_acc: 74.7443%, train_loss: 0.0085
[2023-07-26 17:46:36 - INFO:] test_acc: 78.6585%, test_loss: 0.0079
[2023-07-26 17:46:36 - INFO:] max_train_acc: 74.9148%
[2023-07-26 17:46:36 - INFO:] max_test_acc: 78.7073%
[2023-07-26 17:46:36 - INFO:] max_lr: 0.0050, min_lr: 0.0050
[2023-07-26 17:46:36 - INFO:] ======================================
