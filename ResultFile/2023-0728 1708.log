[2023-0728 1708 - INFO] <<< BEATs_iter3_plus_AS2M >>> - 1 fc layer
[2023-0728 1708 - INFO] # trainset_size = 17010
[2023-0728 1708 - INFO] # testset_size = 22970
[2023-0728 1708 - INFO] # train_a/p = 8505/8505
[2023-0728 1708 - INFO] # test_a/p = 20920/2050
[2023-0728 1708 - INFO] # batch_size = 64
[2023-0728 1708 - INFO] # learning_rate = 0.0001
[2023-0728 1708 - INFO] # num_epochs = 100
[2023-0728 1708 - INFO] # padding_size = 3500
[2023-0728 1708 - INFO] # criterion = CrossEntropyLoss()
[2023-0728 1708 - INFO] # scheduler = None
[2023-0728 1708 - INFO] # optimizer = AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.0001
    maximize: False
    weight_decay: 0.01
)
[2023-0728 1708 - INFO] -------------------------------
[2023-0728 1709 - INFO] epoch: 1/100
[2023-0728 1709 - INFO] learning_rate: 0.0001
[2023-0728 1709 - INFO] train_acc: 66.626%, train_loss: 0.0103
[2023-0728 1709 - INFO] test_acc: 66.626%, test_loss: 0.0102
[2023-0728 1709 - INFO] max_train_acc: 66.626%
[2023-0728 1709 - INFO] max_test_acc: 66.626%
[2023-0728 1709 - INFO] max_lr: 0.0001, min_lr: 0.0001
[2023-0728 1709 - INFO] ======================================
[2023-0728 1710 - INFO] epoch: 2/100
[2023-0728 1710 - INFO] learning_rate: 0.0001
[2023-0728 1710 - INFO] train_acc: 69.459%, train_loss: 0.0097
[2023-0728 1710 - INFO] test_acc: 66.726%, test_loss: 0.0097
[2023-0728 1710 - INFO] max_train_acc: 69.459%
[2023-0728 1710 - INFO] max_test_acc: 66.726%
[2023-0728 1710 - INFO] max_lr: 0.0001, min_lr: 0.0001
[2023-0728 1710 - INFO] ======================================
[2023-0728 1711 - INFO] epoch: 3/100
[2023-0728 1711 - INFO] learning_rate: 0.0001
[2023-0728 1711 - INFO] train_acc: 69.536%, train_loss: 0.0095
[2023-0728 1711 - INFO] test_acc: 66.839%, test_loss: 0.0096
[2023-0728 1711 - INFO] max_train_acc: 69.536%
[2023-0728 1711 - INFO] max_test_acc: 66.839%
[2023-0728 1711 - INFO] max_lr: 0.0001, min_lr: 0.0001
[2023-0728 1711 - INFO] ======================================
[2023-0728 1712 - INFO] epoch: 4/100
[2023-0728 1712 - INFO] learning_rate: 0.0001
[2023-0728 1712 - INFO] train_acc: 69.618%, train_loss: 0.0094
[2023-0728 1712 - INFO] test_acc: 67.444%, test_loss: 0.0092
[2023-0728 1712 - INFO] max_train_acc: 69.618%
[2023-0728 1712 - INFO] max_test_acc: 67.444%
[2023-0728 1712 - INFO] max_lr: 0.0001, min_lr: 0.0001
[2023-0728 1712 - INFO] ======================================
[2023-0728 1713 - INFO] epoch: 5/100
[2023-0728 1713 - INFO] learning_rate: 0.0001
[2023-0728 1713 - INFO] train_acc: 69.900%, train_loss: 0.0093
[2023-0728 1713 - INFO] test_acc: 68.363%, test_loss: 0.0090
[2023-0728 1713 - INFO] max_train_acc: 69.900%
[2023-0728 1713 - INFO] max_test_acc: 68.363%
[2023-0728 1713 - INFO] max_lr: 0.0001, min_lr: 0.0001
[2023-0728 1713 - INFO] ======================================
[2023-0728 1714 - INFO] epoch: 6/100
[2023-0728 1714 - INFO] learning_rate: 0.0001
[2023-0728 1714 - INFO] train_acc: 70.323%, train_loss: 0.0092
[2023-0728 1714 - INFO] test_acc: 69.756%, test_loss: 0.0089
[2023-0728 1714 - INFO] max_train_acc: 70.323%
[2023-0728 1714 - INFO] max_test_acc: 69.756%
[2023-0728 1714 - INFO] max_lr: 0.0001, min_lr: 0.0001
[2023-0728 1714 - INFO] ======================================
[2023-0728 1716 - INFO] epoch: 7/100
[2023-0728 1716 - INFO] learning_rate: 0.0001
[2023-0728 1716 - INFO] train_acc: 70.823%, train_loss: 0.0092
[2023-0728 1716 - INFO] test_acc: 71.489%, test_loss: 0.0088
[2023-0728 1716 - INFO] max_train_acc: 70.823%
[2023-0728 1716 - INFO] max_test_acc: 71.489%
[2023-0728 1716 - INFO] max_lr: 0.0001, min_lr: 0.0001
[2023-0728 1716 - INFO] ======================================
[2023-0728 1717 - INFO] epoch: 8/100
[2023-0728 1717 - INFO] learning_rate: 0.0001
[2023-0728 1717 - INFO] train_acc: 71.305%, train_loss: 0.0091
[2023-0728 1717 - INFO] test_acc: 73.287%, test_loss: 0.0087
[2023-0728 1717 - INFO] max_train_acc: 71.305%
[2023-0728 1717 - INFO] max_test_acc: 73.287%
[2023-0728 1717 - INFO] max_lr: 0.0001, min_lr: 0.0001
[2023-0728 1717 - INFO] ======================================
[2023-0728 1718 - INFO] epoch: 9/100
[2023-0728 1718 - INFO] learning_rate: 0.0001
[2023-0728 1718 - INFO] train_acc: 71.658%, train_loss: 0.0091
[2023-0728 1718 - INFO] test_acc: 75.603%, test_loss: 0.0085
[2023-0728 1718 - INFO] max_train_acc: 71.658%
[2023-0728 1718 - INFO] max_test_acc: 75.603%
[2023-0728 1718 - INFO] max_lr: 0.0001, min_lr: 0.0001
[2023-0728 1718 - INFO] ======================================
[2023-0728 1719 - INFO] epoch: 10/100
[2023-0728 1719 - INFO] learning_rate: 0.0001
[2023-0728 1719 - INFO] train_acc: 72.399%, train_loss: 0.0090
[2023-0728 1719 - INFO] test_acc: 77.148%, test_loss: 0.0084
[2023-0728 1719 - INFO] max_train_acc: 72.399%
[2023-0728 1719 - INFO] max_test_acc: 77.148%
[2023-0728 1719 - INFO] max_lr: 0.0001, min_lr: 0.0001
[2023-0728 1719 - INFO] ======================================
[2023-0728 1720 - INFO] epoch: 11/100
[2023-0728 1720 - INFO] learning_rate: 0.0001
[2023-0728 1720 - INFO] train_acc: 72.616%, train_loss: 0.0090
[2023-0728 1720 - INFO] test_acc: 76.434%, test_loss: 0.0085
[2023-0728 1720 - INFO] max_train_acc: 72.616%
[2023-0728 1720 - INFO] max_test_acc: 77.148%
[2023-0728 1720 - INFO] max_lr: 0.0001, min_lr: 0.0001
[2023-0728 1720 - INFO] ======================================
[2023-0728 1721 - INFO] epoch: 12/100
[2023-0728 1721 - INFO] learning_rate: 0.0001
[2023-0728 1721 - INFO] train_acc: 73.039%, train_loss: 0.0089
[2023-0728 1721 - INFO] test_acc: 77.958%, test_loss: 0.0083
[2023-0728 1721 - INFO] max_train_acc: 73.039%
[2023-0728 1721 - INFO] max_test_acc: 77.958%
[2023-0728 1721 - INFO] max_lr: 0.0001, min_lr: 0.0001
[2023-0728 1721 - INFO] ======================================
[2023-0728 1722 - INFO] epoch: 13/100
[2023-0728 1722 - INFO] learning_rate: 0.0001
[2023-0728 1722 - INFO] train_acc: 73.269%, train_loss: 0.0089
[2023-0728 1722 - INFO] test_acc: 77.993%, test_loss: 0.0083
[2023-0728 1722 - INFO] max_train_acc: 73.269%
[2023-0728 1722 - INFO] max_test_acc: 77.993%
[2023-0728 1722 - INFO] max_lr: 0.0001, min_lr: 0.0001
[2023-0728 1722 - INFO] ======================================
[2023-0728 1723 - INFO] epoch: 14/100
[2023-0728 1723 - INFO] learning_rate: 0.0001
[2023-0728 1723 - INFO] train_acc: 73.410%, train_loss: 0.0089
[2023-0728 1723 - INFO] test_acc: 78.407%, test_loss: 0.0082
[2023-0728 1723 - INFO] max_train_acc: 73.410%
[2023-0728 1723 - INFO] max_test_acc: 78.407%
[2023-0728 1723 - INFO] max_lr: 0.0001, min_lr: 0.0001
[2023-0728 1723 - INFO] ======================================
[2023-0728 1724 - INFO] epoch: 15/100
[2023-0728 1724 - INFO] learning_rate: 0.0001
[2023-0728 1724 - INFO] train_acc: 73.762%, train_loss: 0.0088
[2023-0728 1724 - INFO] test_acc: 79.443%, test_loss: 0.0081
[2023-0728 1724 - INFO] max_train_acc: 73.762%
[2023-0728 1724 - INFO] max_test_acc: 79.443%
[2023-0728 1724 - INFO] max_lr: 0.0001, min_lr: 0.0001
[2023-0728 1724 - INFO] ======================================
[2023-0728 1725 - INFO] epoch: 16/100
[2023-0728 1725 - INFO] learning_rate: 0.0001
[2023-0728 1725 - INFO] train_acc: 73.668%, train_loss: 0.0088
[2023-0728 1725 - INFO] test_acc: 78.929%, test_loss: 0.0082
[2023-0728 1725 - INFO] max_train_acc: 73.762%
[2023-0728 1725 - INFO] max_test_acc: 79.443%
[2023-0728 1725 - INFO] max_lr: 0.0001, min_lr: 0.0001
[2023-0728 1725 - INFO] ======================================
[2023-0728 1726 - INFO] epoch: 17/100
[2023-0728 1726 - INFO] learning_rate: 0.0001
[2023-0728 1726 - INFO] train_acc: 74.186%, train_loss: 0.0088
[2023-0728 1726 - INFO] test_acc: 79.595%, test_loss: 0.0081
[2023-0728 1726 - INFO] max_train_acc: 74.186%
[2023-0728 1726 - INFO] max_test_acc: 79.595%
[2023-0728 1726 - INFO] max_lr: 0.0001, min_lr: 0.0001
[2023-0728 1726 - INFO] ======================================
[2023-0728 1727 - INFO] epoch: 18/100
[2023-0728 1727 - INFO] learning_rate: 0.0001
[2023-0728 1727 - INFO] train_acc: 74.004%, train_loss: 0.0088
[2023-0728 1727 - INFO] test_acc: 79.599%, test_loss: 0.0081
[2023-0728 1727 - INFO] max_train_acc: 74.186%
[2023-0728 1727 - INFO] max_test_acc: 79.599%
[2023-0728 1727 - INFO] max_lr: 0.0001, min_lr: 0.0001
[2023-0728 1727 - INFO] ======================================
