[2023-0804 1050 - INFO] <<< BEATs_iter3_plus_AS2M - 2 fc layer >>> 
[2023-0804 1050 - INFO] Add FrequencyMasking and TimeMasking
[2023-0804 1050 - INFO] Add time_stretch 0.8 and time_stretch 1.2
[2023-0804 1050 - INFO] # trainset_size = 17010
[2023-0804 1050 - INFO] # testset_size = 27070
[2023-0804 1050 - INFO] # train_a/p = 8505/8505
[2023-0804 1050 - INFO] # test_a/p = 20920/6150
[2023-0804 1050 - INFO] # batch_size = 128
[2023-0804 1050 - INFO] # learning_rate = 0.005
[2023-0804 1050 - INFO] # num_epochs = 100
[2023-0804 1050 - INFO] # padding_size = 3500
[2023-0804 1050 - INFO] # loss_fn = CE
[2023-0804 1050 - INFO] # scheduler = None
[2023-0804 1050 - INFO] # optimizer = AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.999)
    capturable: False
    differentiable: False
    eps: 1e-08
    foreach: None
    fused: None
    lr: 0.005
    maximize: False
    weight_decay: 0.01
)
[2023-0804 1050 - INFO] -------------------------------------
[2023-0804 1101 - INFO] epoch: 1/100
[2023-0804 1101 - INFO] learning_rate: 0.0050
[2023-0804 1101 - INFO] train_acc: 49.647%, train_loss: nan
[2023-0804 1101 - INFO] test_acc: 23.110%, test_loss: 0.0058
[2023-0804 1101 - INFO] max_train_acc: 49.647%
[2023-0804 1101 - INFO] max_test_acc: 23.110%
[2023-0804 1101 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1101 - INFO] ======================================
[2023-0804 1104 - INFO] epoch: 2/100
[2023-0804 1104 - INFO] learning_rate: 0.0050
[2023-0804 1104 - INFO] train_acc: 49.677%, train_loss: nan
[2023-0804 1104 - INFO] test_acc: 23.221%, test_loss: 0.0058
[2023-0804 1104 - INFO] max_train_acc: 49.677%
[2023-0804 1104 - INFO] max_test_acc: 23.221%
[2023-0804 1104 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1104 - INFO] ======================================
[2023-0804 1106 - INFO] epoch: 3/100
[2023-0804 1106 - INFO] learning_rate: 0.0050
[2023-0804 1106 - INFO] train_acc: 49.706%, train_loss: nan
[2023-0804 1106 - INFO] test_acc: 23.022%, test_loss: 0.0058
[2023-0804 1106 - INFO] max_train_acc: 49.706%
[2023-0804 1106 - INFO] max_test_acc: 23.221%
[2023-0804 1106 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1106 - INFO] ======================================
[2023-0804 1107 - INFO] epoch: 4/100
[2023-0804 1107 - INFO] learning_rate: 0.0050
[2023-0804 1107 - INFO] train_acc: 49.653%, train_loss: nan
[2023-0804 1107 - INFO] test_acc: 23.018%, test_loss: 0.0058
[2023-0804 1107 - INFO] max_train_acc: 49.706%
[2023-0804 1107 - INFO] max_test_acc: 23.221%
[2023-0804 1107 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1107 - INFO] ======================================
[2023-0804 1109 - INFO] epoch: 5/100
[2023-0804 1109 - INFO] learning_rate: 0.0050
[2023-0804 1109 - INFO] train_acc: 49.612%, train_loss: nan
[2023-0804 1109 - INFO] test_acc: 23.158%, test_loss: 0.0058
[2023-0804 1109 - INFO] max_train_acc: 49.706%
[2023-0804 1109 - INFO] max_test_acc: 23.221%
[2023-0804 1109 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1109 - INFO] ======================================
[2023-0804 1110 - INFO] epoch: 6/100
[2023-0804 1110 - INFO] learning_rate: 0.0050
[2023-0804 1110 - INFO] train_acc: 49.724%, train_loss: nan
[2023-0804 1110 - INFO] test_acc: 22.944%, test_loss: 0.0058
[2023-0804 1110 - INFO] max_train_acc: 49.724%
[2023-0804 1110 - INFO] max_test_acc: 23.221%
[2023-0804 1110 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1110 - INFO] ======================================
[2023-0804 1112 - INFO] epoch: 7/100
[2023-0804 1112 - INFO] learning_rate: 0.0050
[2023-0804 1112 - INFO] train_acc: 49.630%, train_loss: nan
[2023-0804 1112 - INFO] test_acc: 23.018%, test_loss: 0.0058
[2023-0804 1112 - INFO] max_train_acc: 49.724%
[2023-0804 1112 - INFO] max_test_acc: 23.221%
[2023-0804 1112 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1112 - INFO] ======================================
[2023-0804 1113 - INFO] epoch: 8/100
[2023-0804 1113 - INFO] learning_rate: 0.0050
[2023-0804 1113 - INFO] train_acc: 49.624%, train_loss: nan
[2023-0804 1113 - INFO] test_acc: 23.048%, test_loss: 0.0058
[2023-0804 1113 - INFO] max_train_acc: 49.724%
[2023-0804 1113 - INFO] max_test_acc: 23.221%
[2023-0804 1113 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1113 - INFO] ======================================
[2023-0804 1115 - INFO] epoch: 9/100
[2023-0804 1115 - INFO] learning_rate: 0.0050
[2023-0804 1115 - INFO] train_acc: 49.653%, train_loss: nan
[2023-0804 1115 - INFO] test_acc: 23.085%, test_loss: 0.0058
[2023-0804 1115 - INFO] max_train_acc: 49.724%
[2023-0804 1115 - INFO] max_test_acc: 23.221%
[2023-0804 1115 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1115 - INFO] ======================================
[2023-0804 1116 - INFO] epoch: 10/100
[2023-0804 1116 - INFO] learning_rate: 0.0050
[2023-0804 1116 - INFO] train_acc: 49.700%, train_loss: nan
[2023-0804 1116 - INFO] test_acc: 22.926%, test_loss: 0.0058
[2023-0804 1116 - INFO] max_train_acc: 49.724%
[2023-0804 1116 - INFO] max_test_acc: 23.221%
[2023-0804 1116 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1116 - INFO] ======================================
[2023-0804 1118 - INFO] epoch: 11/100
[2023-0804 1118 - INFO] learning_rate: 0.0050
[2023-0804 1118 - INFO] train_acc: 49.671%, train_loss: nan
[2023-0804 1118 - INFO] test_acc: 23.070%, test_loss: 0.0058
[2023-0804 1118 - INFO] max_train_acc: 49.724%
[2023-0804 1118 - INFO] max_test_acc: 23.221%
[2023-0804 1118 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1118 - INFO] ======================================
[2023-0804 1119 - INFO] epoch: 12/100
[2023-0804 1119 - INFO] learning_rate: 0.0050
[2023-0804 1119 - INFO] train_acc: 49.700%, train_loss: nan
[2023-0804 1119 - INFO] test_acc: 22.918%, test_loss: 0.0058
[2023-0804 1119 - INFO] max_train_acc: 49.724%
[2023-0804 1119 - INFO] max_test_acc: 23.221%
[2023-0804 1119 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1119 - INFO] ======================================
[2023-0804 1120 - INFO] epoch: 13/100
[2023-0804 1120 - INFO] learning_rate: 0.0050
[2023-0804 1120 - INFO] train_acc: 49.653%, train_loss: nan
[2023-0804 1120 - INFO] test_acc: 23.181%, test_loss: 0.0058
[2023-0804 1120 - INFO] max_train_acc: 49.724%
[2023-0804 1120 - INFO] max_test_acc: 23.221%
[2023-0804 1120 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1120 - INFO] ======================================
[2023-0804 1122 - INFO] epoch: 14/100
[2023-0804 1122 - INFO] learning_rate: 0.0050
[2023-0804 1122 - INFO] train_acc: 49.624%, train_loss: nan
[2023-0804 1122 - INFO] test_acc: 23.129%, test_loss: 0.0058
[2023-0804 1122 - INFO] max_train_acc: 49.724%
[2023-0804 1122 - INFO] max_test_acc: 23.221%
[2023-0804 1122 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1122 - INFO] ======================================
[2023-0804 1123 - INFO] epoch: 15/100
[2023-0804 1123 - INFO] learning_rate: 0.0050
[2023-0804 1123 - INFO] train_acc: 49.677%, train_loss: nan
[2023-0804 1123 - INFO] test_acc: 23.014%, test_loss: 0.0058
[2023-0804 1123 - INFO] max_train_acc: 49.724%
[2023-0804 1123 - INFO] max_test_acc: 23.221%
[2023-0804 1123 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1123 - INFO] ======================================
[2023-0804 1125 - INFO] epoch: 16/100
[2023-0804 1125 - INFO] learning_rate: 0.0050
[2023-0804 1125 - INFO] train_acc: 49.612%, train_loss: nan
[2023-0804 1125 - INFO] test_acc: 22.959%, test_loss: 0.0058
[2023-0804 1125 - INFO] max_train_acc: 49.724%
[2023-0804 1125 - INFO] max_test_acc: 23.221%
[2023-0804 1125 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1125 - INFO] ======================================
[2023-0804 1126 - INFO] epoch: 17/100
[2023-0804 1126 - INFO] learning_rate: 0.0050
[2023-0804 1126 - INFO] train_acc: 49.659%, train_loss: nan
[2023-0804 1126 - INFO] test_acc: 23.037%, test_loss: 0.0058
[2023-0804 1126 - INFO] max_train_acc: 49.724%
[2023-0804 1126 - INFO] max_test_acc: 23.221%
[2023-0804 1126 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1126 - INFO] ======================================
[2023-0804 1128 - INFO] epoch: 18/100
[2023-0804 1128 - INFO] learning_rate: 0.0050
[2023-0804 1128 - INFO] train_acc: 49.641%, train_loss: nan
[2023-0804 1128 - INFO] test_acc: 23.140%, test_loss: 0.0058
[2023-0804 1128 - INFO] max_train_acc: 49.724%
[2023-0804 1128 - INFO] max_test_acc: 23.221%
[2023-0804 1128 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1128 - INFO] ======================================
[2023-0804 1129 - INFO] epoch: 19/100
[2023-0804 1129 - INFO] learning_rate: 0.0050
[2023-0804 1129 - INFO] train_acc: 49.683%, train_loss: nan
[2023-0804 1129 - INFO] test_acc: 23.107%, test_loss: 0.0058
[2023-0804 1129 - INFO] max_train_acc: 49.724%
[2023-0804 1129 - INFO] max_test_acc: 23.221%
[2023-0804 1129 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1129 - INFO] ======================================
[2023-0804 1131 - INFO] epoch: 20/100
[2023-0804 1131 - INFO] learning_rate: 0.0050
[2023-0804 1131 - INFO] train_acc: 49.712%, train_loss: nan
[2023-0804 1131 - INFO] test_acc: 23.044%, test_loss: 0.0058
[2023-0804 1131 - INFO] max_train_acc: 49.724%
[2023-0804 1131 - INFO] max_test_acc: 23.221%
[2023-0804 1131 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1131 - INFO] ======================================
[2023-0804 1132 - INFO] epoch: 21/100
[2023-0804 1132 - INFO] learning_rate: 0.0050
[2023-0804 1132 - INFO] train_acc: 49.671%, train_loss: nan
[2023-0804 1132 - INFO] test_acc: 22.952%, test_loss: 0.0058
[2023-0804 1132 - INFO] max_train_acc: 49.724%
[2023-0804 1132 - INFO] max_test_acc: 23.221%
[2023-0804 1132 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1132 - INFO] ======================================
[2023-0804 1134 - INFO] epoch: 22/100
[2023-0804 1134 - INFO] learning_rate: 0.0050
[2023-0804 1134 - INFO] train_acc: 49.636%, train_loss: nan
[2023-0804 1134 - INFO] test_acc: 23.029%, test_loss: 0.0058
[2023-0804 1134 - INFO] max_train_acc: 49.724%
[2023-0804 1134 - INFO] max_test_acc: 23.221%
[2023-0804 1134 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1134 - INFO] ======================================
[2023-0804 1135 - INFO] epoch: 23/100
[2023-0804 1135 - INFO] learning_rate: 0.0050
[2023-0804 1135 - INFO] train_acc: 49.630%, train_loss: nan
[2023-0804 1135 - INFO] test_acc: 23.037%, test_loss: 0.0058
[2023-0804 1135 - INFO] max_train_acc: 49.724%
[2023-0804 1135 - INFO] max_test_acc: 23.221%
[2023-0804 1135 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1135 - INFO] ======================================
[2023-0804 1137 - INFO] epoch: 24/100
[2023-0804 1137 - INFO] learning_rate: 0.0050
[2023-0804 1137 - INFO] train_acc: 49.677%, train_loss: nan
[2023-0804 1137 - INFO] test_acc: 23.059%, test_loss: 0.0058
[2023-0804 1137 - INFO] max_train_acc: 49.724%
[2023-0804 1137 - INFO] max_test_acc: 23.221%
[2023-0804 1137 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1137 - INFO] ======================================
[2023-0804 1138 - INFO] epoch: 25/100
[2023-0804 1138 - INFO] learning_rate: 0.0050
[2023-0804 1138 - INFO] train_acc: 49.688%, train_loss: nan
[2023-0804 1138 - INFO] test_acc: 23.037%, test_loss: 0.0058
[2023-0804 1138 - INFO] max_train_acc: 49.724%
[2023-0804 1138 - INFO] max_test_acc: 23.221%
[2023-0804 1138 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1138 - INFO] ======================================
[2023-0804 1139 - INFO] epoch: 26/100
[2023-0804 1139 - INFO] learning_rate: 0.0050
[2023-0804 1139 - INFO] train_acc: 49.741%, train_loss: nan
[2023-0804 1139 - INFO] test_acc: 22.952%, test_loss: 0.0058
[2023-0804 1139 - INFO] max_train_acc: 49.741%
[2023-0804 1139 - INFO] max_test_acc: 23.221%
[2023-0804 1139 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1139 - INFO] ======================================
[2023-0804 1141 - INFO] epoch: 27/100
[2023-0804 1141 - INFO] learning_rate: 0.0050
[2023-0804 1141 - INFO] train_acc: 49.688%, train_loss: nan
[2023-0804 1141 - INFO] test_acc: 22.952%, test_loss: 0.0058
[2023-0804 1141 - INFO] max_train_acc: 49.741%
[2023-0804 1141 - INFO] max_test_acc: 23.221%
[2023-0804 1141 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1141 - INFO] ======================================
[2023-0804 1142 - INFO] epoch: 28/100
[2023-0804 1142 - INFO] learning_rate: 0.0050
[2023-0804 1142 - INFO] train_acc: 49.730%, train_loss: nan
[2023-0804 1142 - INFO] test_acc: 23.037%, test_loss: 0.0058
[2023-0804 1142 - INFO] max_train_acc: 49.741%
[2023-0804 1142 - INFO] max_test_acc: 23.221%
[2023-0804 1142 - INFO] max_lr: 0.0050, min_lr: 0.0050
[2023-0804 1142 - INFO] ======================================
