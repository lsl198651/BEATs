{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "file_path=r'E:\\Shilong\\murmur\\circor_dataset_period\\Absent\\2530\\2530_AV'\n",
    "for root,dir,file in os.walk(file_path):\n",
    "    for subfile in file:\n",
    "        files=os.path.join(root,subfile)\n",
    "        state=subfile.split(\"_\")\n",
    "        \n",
    "        print(state[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "def mfcc_feature(filename,sr=4000,nmfcc=13):\n",
    "    data, samprate = librosa.load(filename)\n",
    "    # 提取 MFCC feature\n",
    "    mfcc = librosa.feature.mfcc(y=data, sr=samprate, n_mfcc=nmfcc)\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path=r'E:\\Shilong\\murmur\\circor_dataset_period\\train'\n",
    "for root,dir,file in os.walk(path):\n",
    "    for subdir in file:\n",
    "        sub_dir=os.path.join(root,subdir)\n",
    "        mfccc=mfcc_feature(sub_dir)\n",
    "        print(mfccc.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "diastolic=list()\n",
    "systolic=list()\n",
    "s1=list()\n",
    "s2=list()\n",
    "\n",
    "\n",
    "file_path=r'E:\\Shilong\\murmur\\circor_dataset_period\\train'\n",
    "for root,dir,file in os.walk(file_path):\n",
    "    for subfile in file:\n",
    "        files=os.path.join(root,subfile)\n",
    "        print(files)\n",
    "        mfccc=mfcc_feature(files)\n",
    "        state=subfile.split(\"_\")        \n",
    "        if state[0]=='diastolic':\n",
    "            diastolic.append(mfccc.shape[1])\n",
    "        if state[0]=='systolic':\n",
    "            systolic.append(mfccc.shape[1])\n",
    "        if state[0]=='s1':\n",
    "            s1.append(mfccc.shape[1])\n",
    "        if state[0]=='s2':\n",
    "            s2.append(mfccc.shape[1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the csv row_num-th row\n",
    "def csv_reader_row(file_name,row_num):\n",
    "    with open(file_name, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        row=list(reader)\n",
    "    return row[row_num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv file by column\n",
    "# train_csv=pd.read_csv(\"F:/heart_data/2022_challenge/heart/training_data.csv\",sep=',')\n",
    "def csv_reader_cl(file_name,clo_num):\n",
    "    with open(file_name,encoding='utf-8') as csvfile:\n",
    "        reader=csv.reader(csvfile)\n",
    "        column=[row[clo_num] for row in reader]\n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_if(x):\n",
    "    # y=list()\n",
    "    if x == \"Absent\\\\\":\n",
    "        y = np.array([[1]])\n",
    "    elif x == \"Present\\\\\":\n",
    "        y = np.array([[0]])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "n_input=13\n",
    "file_path=r'E:\\Shilong\\murmur\\circor_dataset_period\\train'\n",
    "for root,dir,file in os.walk(file_path):\n",
    "    for subfile in file:\n",
    "        files=os.path.join(root,subfile)\n",
    "        print(subfile)\n",
    "        # mfcck=mfcc_feature(files)\n",
    "        # output = switch_if(mur)   \n",
    "        # # print(mfcck.size)         \n",
    "        # mfcck_1 = mfcck.reshape(1,mfcck.size)\n",
    "        # if(mfcck.size<=n_input):\n",
    "        #     #补至104，其余补0\n",
    "        #     mfcck_2 = np.pad(mfcck_1, (0, n_input-mfcck.size), 'constant', constant_values=(0, 0))\n",
    "        #     all = np.hstack((output,mfcck_2))                    \n",
    "        #     WAV_feature = np.vstack((WAV_feature,all))\n",
    "        #     length_file = length_file + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.max(diastolic),np.min(diastolic),np.mean(diastolic))\n",
    "print(np.max(systolic),np.min(systolic),np.mean(systolic))\n",
    "print(np.max(s1),np.min(s1),np.mean(s1))\n",
    "print(np.max(s2),np.min(s2),np.mean(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Shilong\n",
    "# Creat Data: 2023-6-16\n",
    "# Modify Date:2023-\n",
    "# Description: load fin-tuned BEATs model  \n",
    "\"\"\"\n",
    "Load Tokenizers\n",
    "\"\"\"\n",
    "\n",
    "# import torch\n",
    "# from Tokenizers import TokenizersConfig, Tokenizers\n",
    "\n",
    "# # load the pre-trained checkpoints\n",
    "# checkpoint = torch.load(r'E:\\Shilong\\murmur\\03_Classifier\\LM\\BEATs\\Tokenizer_iter2.pt')\n",
    "\n",
    "# cfg = TokenizersConfig(checkpoint['cfg'])\n",
    "# BEATs_tokenizer = Tokenizers(cfg)\n",
    "# BEATs_tokenizer.load_state_dict(checkpoint['model'])\n",
    "# BEATs_tokenizer.eval()\n",
    "\n",
    "# # tokenize the audio and generate the labels\n",
    "# audio_input_16khz = torch.randn(1, 10000)\n",
    "# padding_mask = torch.zeros(1, 10000).bool()\n",
    "\n",
    "# labels = BEATs_tokenizer.extract_labels(audio_input_16khz, padding_mask=padding_mask)\n",
    "\n",
    "\"\"\"\n",
    "Load Pre-Trained Models\n",
    "\"\"\"\n",
    "# %matplotlib inline\n",
    "import torch,os,torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, models, transforms\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "torch.__version__\n",
    "import csv\n",
    "import librosa\n",
    "from BEATs import BEATs, BEATsConfig\n",
    "from BEATs_def import get_patientid\n",
    "\n",
    "print(\"========================load data========================\")\n",
    "murmur_positoin=['_AV','_MV','_PV','_TV']\n",
    "murmur_ap=[\"Absent\\\\\",\"Present\\\\\"]\n",
    "period=[\"s1\", \"systolic\", \"s2\", \"diastolic\"]\n",
    "\n",
    "file_path=r'E:\\Shilong\\murmur\\circor_dataset_period\\train'\n",
    "# get absent / present patient_id\n",
    "absent_csv=r'E:\\Shilong\\murmur\\03_Classifier\\MurmurDectection\\absent_id.csv'\n",
    "present_csv=r'E:\\Shilong\\murmur\\03_Classifier\\MurmurDectection\\present_id.csv'\n",
    "absent_patient_id=get_patientid(absent_csv)\n",
    "present_patient_id=get_patientid(present_csv)\n",
    "\n",
    "print(\"========================load model==========================\")\n",
    "\n",
    "# load the pre-trained checkpoints\n",
    "checkpoint = torch.load(r'E:\\Shilong\\murmur\\03_Classifier\\LM\\BEATs\\BEATs_iter2.pt')\n",
    "\n",
    "cfg = BEATsConfig(checkpoint['cfg'])\n",
    "BEATs_model = BEATs(cfg)\n",
    "BEATs_model.load_state_dict(checkpoint['model'])\n",
    "BEATs_model.eval()\n",
    "# extract the the audio representation\n",
    "audio_input_16khz = torch.randn(1, 10000)\n",
    "padding_mask = torch.zeros(1, 10000).bool()\n",
    "\n",
    "# representation = BEATs_model.extract_features(audio_input_16khz, padding_mask=padding_mask)[0]\n",
    "\n",
    "print(\"========================extract features==========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r'E:\\Shilong\\murmur\\circor_dataset_period'\n",
    "for mur in murmur_ap:\n",
    "    for patient_id in absent_patient_id:\n",
    "        for pos in murmur_positoin:\n",
    "            dir_path=path+\"\\\\\"+mur+patient_id+\"\\\\\"+patient_id+pos\n",
    "            wav_path=dir_path+\".wav\"\n",
    "            print(\"wav_path\"+wav_path)\n",
    "            if os.path.exists(wav_path):\n",
    "                y, sr = librosa.load(wav_path, sr=2000)\n",
    "                # y_16k = librosa.resample(y, sr, 16000)\n",
    "                wav = torch.tensor(y)\n",
    "                # 增加一个维度满足输入要求\n",
    "                wav = wav.unsqueeze(0)\n",
    "                rep = BEATs_model.extract_features(wav)[0]\n",
    "                rep = torch.squeeze(rep).detach().cpu().numpy()\n",
    "                feature = pd.DataFrame(rep)\n",
    "                save_path = path + \"\\\\\" + mur + \"\\\\\" + patient_id +\"\\\\\"+ patient_id + pos+ \".csv\"\n",
    "                print(\"save_path\"+save_path)\n",
    "                feature.to_csv(save_path, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=r'E:\\Shilong\\murmur\\circor_dataset_period'\n",
    "def get_mfcc_features(mur,path,id=present_patient_id,position=murmur_positoin):    \n",
    "    for patient_id in id:\n",
    "        for pos in position:\n",
    "            dir_path=path+\"\\\\\"+mur+patient_id+\"\\\\\"+patient_id+pos\n",
    "            wav_path=dir_path+\".wav\"\n",
    "            print(\"wav_path\"+wav_path)\n",
    "            if os.path.exists(wav_path):\n",
    "                y, sr = librosa.load(wav_path, sr=2000)\n",
    "                # y_16k = librosa.resample(y, sr, 16000)\n",
    "                wav = torch.tensor(y)\n",
    "                # 增加一个维度满足输入要求\n",
    "                wav = wav.unsqueeze(0)\n",
    "                rep = BEATs_model.extract_features(wav)[0]\n",
    "                rep = torch.squeeze(rep).detach().cpu().numpy()\n",
    "                feature = pd.DataFrame(rep)\n",
    "                save_path = path + \"\\\\\" + mur + \"\\\\\" + patient_id +\"\\\\\"+ patient_id + pos+ \".csv\"\n",
    "                print(\"save_path\"+save_path)\n",
    "                feature.to_csv(save_path, index=False, header=False)\n",
    "    return feature\n",
    "absent_features=feature\n",
    "# absent_features=get_mfcc_features(murmur_ap[0],filepath,present_patient_id)# absent\n",
    "present_features=get_mfcc_features(murmur_ap[1],filepath,present_patient_id)# present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile\n",
    "import numpy as np\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_load(tsvname):\n",
    "   #读取tsv文件内容,不需要close函数\n",
    "   with open(tsvname, 'r') as f:\n",
    "    txt_data = f.read()\n",
    "    head=['start','end','period']\n",
    "    data=txt_data.split('\\n')[:-1]\n",
    "    #遍历每一行\n",
    "    for l in data:\n",
    "        sgmt=l.split('\\t')\n",
    "        if sgmt[2]!='0':\n",
    "            head=np.vstack([head,sgmt])\n",
    "   return head[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch period\n",
    "def switch_period(period):\n",
    "    if  period=='1':\n",
    "        location=\"s1\"\n",
    "        # num1=num1+1\n",
    "\n",
    "    elif  period=='2':\n",
    "        location=\"systolic\"\n",
    "        # num2=num2+1\n",
    "\n",
    "    elif  period=='3':\n",
    "        location=\"s2\"\n",
    "        # num3=num3+1\n",
    "\n",
    "    elif  period=='4':\n",
    "        location=\"diastolic\"\n",
    "        # num4=num4+1\n",
    "\n",
    "    return location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessed PCGs were segmented into four heart sound states\n",
    "def state_div(tsvname,wavname,state_path,index):\n",
    "    # 获取周期时间点\n",
    "    # type:array\n",
    "    index_file=index_load(tsvname)\n",
    "    # print(index_file)\n",
    "    # 获取array长度：a.shape[0]\n",
    "    # 分割音频\n",
    "    # states_num=[0,0,0,0]\n",
    "    num=0\n",
    "\n",
    "    for i in range(index_file.shape[0]-3):\n",
    "        if index_file[i][2]=='1'and index_file[i+3][2]=='4':\n",
    "            start_index=float(index_file[i][0])*1000\n",
    "            end_index=float(index_file[i+3][1])*1000\n",
    "            num=num+1\n",
    "        print(start_index,end_index)\n",
    "        # print(\"wav index\")\n",
    "        # print(wav_index)\n",
    "        \n",
    "        # print(start_index,end_index)\n",
    "        # period_index=wav_index[2]\n",
    "        \n",
    "        # states_index=switch_period(wav_index[2])\n",
    "        recording, fs = librosa.load(wavname,sr=1000)\n",
    "        print(\"================================================================\")\n",
    "        # print(\"wav name: \"+wavname)\n",
    "        # print(\"fs is: \"+str(fs))\n",
    "\n",
    "        buff = recording[int(start_index) :  int(end_index) ]  # 字符串索引切割\n",
    "        # print(\"buff len: \"+str(len(buff)))\n",
    "        # print(\"buff : \"+str(buff))\n",
    "        # print(buff)\n",
    "        # buff.export(folder_path+mur+patient_id+\"\\\\\"+patient_id+pos+\"{}{}+.wav\".format(period_index,i), format=\"wav\")\n",
    "        # cut.append(buff)\n",
    "        soundfile.write(state_path+\"{}_{}.wav\".format(index,num),buff,fs)\n",
    "\n",
    "# tsv=r'E:\\Shilong\\murmur\\LM_wav_dataset\\Absent\\2530\\2530_TV.tsv'\n",
    "# wav=r'E:\\Shilong\\murmur\\LM_wav_dataset\\Absent\\2530\\2530_TV.wav'\n",
    "# path=\"E:\\\\Shilong\\\\murmur\\\\LM_wav_dataset\\\\Absent\\\\2530\\\\\"\n",
    "# state_div(tsv,wav,path,'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 切数据，命名格式为：id+pos+state+num\n",
    "positoin=['_AV','_MV','_PV','_TV']\n",
    "murmur=[\"Absent\\\\\",\"Present\\\\\"]\n",
    "folder_path=r'E:\\Shilong\\murmur\\LM_wav_dataset\\\\'\n",
    "# file_path=folder_path+mur+patient_id+patient_id+pos+\".tsv\"\n",
    "# path=\"E:\\\\01_Work\\\\02_SoftwareDesign\\\\circor_dataset_period\\\\\"\n",
    "def period_div(path,murmur,patient_id_list,positoin):\n",
    "    for mur in murmur:\n",
    "        for patient_id in patient_id_list:\n",
    "            for pos in positoin:\n",
    "                dir_path=path+mur+patient_id+\"\\\\\"+patient_id+pos\n",
    "                tsv_path=dir_path+\".tsv\"\n",
    "                wav_path=dir_path+\".wav\"\n",
    "                if os.path.exists(tsv_path):\n",
    "                    state_div(tsv_path,wav_path,dir_path+\"\\\\\",patient_id+pos)\n",
    "\n",
    "period_div(folder_path,murmur,absent_patient_id,positoin)\n",
    "period_div(folder_path,murmur,present_patient_id,positoin)\n",
    "# period_div(folder_path,murmur,unknown_patient_id,positoin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv=r'E:\\Shilong\\murmur\\LM_wav_dataset\\Absent\\2530\\2530_TV.tsv'\n",
    "index=index_load(tsv)\n",
    "index[1][2]\n",
    "index.shape[0]\n",
    "for i in range(index.shape[0]-3):\n",
    "    if index[i][2]=='1'and index[i+3][2]=='4':\n",
    "        start=index[i][0]\n",
    "        end=index[i+3][1]\n",
    "        print(start,end)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "# file_name=r'E:\\Shilong\\murmur\\LM_wav_dataset\\train_csv\\2530_AV_1.wav.csv'\n",
    "import pandas as pd\n",
    "filename = r'E:\\Shilong\\murmur\\LM_wav_dataset\\train_csv\\2530_AV_1.wav.csv'\n",
    "df = pd.read_csv(filename,header=None)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a=np.array(['1','1','1'])\n",
    "type(a)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存训练日志文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_log_filename = \"train_log.txt\"\n",
    "train_log_filepath = os.path.join(result_dir, train_log_filename)\n",
    "train_log_txt_formatter = \"{time_str} [Epoch] {epoch:03d} [Loss] {loss_str}\\n\"\n",
    "to_write=train_log_txt_formatter.format(time_str=time.strtime(%Y_%n_%d_%H:%M:%S),\n",
    "                                        epoch=epoch,\n",
    "                                        loss_str=\" \".join([\"{}\".format(loss)]))\n",
    "with open(train_log_filepath,\"a\") as f:\n",
    "    f.write(to_write)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存训练变量（dataloader）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./train_loader.pkl','wb') as f:\n",
    "    dill.dump(dataset,f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(train_features,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a=torch.zeros(2, 10000).bool()\n",
    "a"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load NPY文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "loadData = np.load(r'E:\\Shilong\\murmur\\03_Classifier\\test_features.npy')\n",
    "\n",
    "print(\"----type----\")\n",
    "print(type(loadData))\n",
    "print(\"----shape----\")\n",
    "print(loadData.shape)\n",
    "print(\"----data----\")\n",
    "print(loadData)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def draw_confusion_matrix(label_true, label_pred, label_name, normlize, title=\"Confusion Matrix\", pdf_save_path=None, dpi=100):\n",
    "    \"\"\"\n",
    "\n",
    "    @param label_true: 真实标签，比如[0,1,2,7,4,5,...]\n",
    "    @param label_pred: 预测标签，比如[0,5,4,2,1,4,...]\n",
    "    @param label_name: 标签名字，比如['cat','dog','flower',...]\n",
    "    @param normlize: 是否设元素为百分比形式\n",
    "    @param title: 图标题\n",
    "    @param pdf_save_path: 是否保存，是则为保存路径pdf_save_path=xxx.png | xxx.pdf | ...等其他plt.savefig支持的保存格式\n",
    "    @param dpi: 保存到文件的分辨率，论文一般要求至少300dpi\n",
    "    @return:\n",
    "\n",
    "    example：\n",
    "            draw_confusion_matrix(label_true=y_gt,\n",
    "                          label_pred=y_pred,\n",
    "                          label_name=[\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"],\n",
    "                          normlize=True,\n",
    "                          title=\"Confusion Matrix on Fer2013\",\n",
    "                          pdf_save_path=\"Confusion_Matrix_on_Fer2013.png\",\n",
    "                          dpi=300)\n",
    "\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(label_true, label_pred)\n",
    "    if normlize:\n",
    "        row_sums = np.sum(cm, axis=1)  # 计算每行的和\n",
    "        cm = cm / row_sums[:, np.newaxis]  # 广播计算每个元素占比\n",
    "    cm=cm.T\n",
    "    plt.imshow(cm, cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predict label\")\n",
    "    plt.ylabel(\"Truth label\")\n",
    "    plt.yticks(range(label_name.__len__()), label_name)\n",
    "    plt.xticks(range(label_name.__len__()), label_name, rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.colorbar()\n",
    "\n",
    "    for i in range(label_name.__len__()):\n",
    "        for j in range(label_name.__len__()):\n",
    "            color = (1, 1, 1) if i == j else (0, 0, 0)\t# 对角线字体白色，其他黑色\n",
    "            value = float(format('%.2f' % cm[i, j]))\n",
    "            plt.text(i, j, value, verticalalignment='center', horizontalalignment='center', color=color)\n",
    "\n",
    "    # plt.show()\n",
    "    if not pdf_save_path is None:\n",
    "        plt.savefig(pdf_save_path, bbox_inches='tight',dpi=dpi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_name=['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "\n",
    "y_gt=[]\n",
    "y_pred=[]\n",
    "for index, (labels, imgs) in enumerate(test_loader):\n",
    "    labels_pd = model(imgs)\n",
    "    predict_np = np.argmax(labels_pd.cpu().detach().numpy(), axis=-1)   # array([0,5,1,6,3,...],dtype=int64)\n",
    "    labels_np = labels.numpy()                                          # array([0,5,0,6,2,...],dtype=int64)\n",
    "\t\n",
    "    y_pred.append(labels_np)\n",
    "    y_gt.append(labels_np)\n",
    "    \n",
    "draw_confusion_matrix(label_true=y_gt,\t\t\t# y_gt=[0,5,1,6,3,...]\n",
    "                      label_pred=y_pred,\t    # y_pred=[0,5,1,6,3,...]\n",
    "                      label_name=[\"An\", \"Di\", \"Fe\", \"Ha\", \"Sa\", \"Su\", \"Ne\"],\n",
    "                      normlize=True,\n",
    "                      title=\"Confusion Matrix on Fer2013\",\n",
    "                      pdf_save_path=\"Confusion_Matrix_on_Fer2013.jpg\",\n",
    "                      dpi=300)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 召回率计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "pred = [0, 1, 0, 1] # 预测的值\n",
    "target = [0, 1, 1, 0] # 真实的值\n",
    "\n",
    "r = recall_score(pred, target)\n",
    "\n",
    "print(r)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果不是 0 1 的值，是其他二分类的值，那么就可以通过 labels、pos_label 来指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [3,4]  # 二分类 两个类别的值\n",
    "\n",
    "pred = [3, 4, 3, 4] # 预测的值\n",
    "\n",
    "target = [3, 4, 4, 3] # 真实的值\n",
    "\n",
    "r = recall_score(pred, target , labels = labels , pos_label= 3) # pos_label指定正样本的值是多少\n",
    "\n",
    "print(r)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化\n",
    "YAMNet 还会返回一些可用于可视化的附加信息。我们看一下波形、声谱图和推断的热门类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the waveform.\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(waveform)\n",
    "plt.xlim([0, len(waveform)])\n",
    "\n",
    "# Plot the log-mel spectrogram (returned by the model).\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.imshow(spectrogram_np.T, aspect='auto', interpolation='nearest', origin='lower')\n",
    "\n",
    "# Plot and label the model output scores for the top-scoring classes.\n",
    "mean_scores = np.mean(scores, axis=0)\n",
    "top_n = 10\n",
    "top_class_indices = np.argsort(mean_scores)[::-1][:top_n]\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.imshow(scores_np[:, top_class_indices].T, aspect='auto', interpolation='nearest', cmap='gray_r')\n",
    "\n",
    "# patch_padding = (PATCH_WINDOW_SECONDS / 2) / PATCH_HOP_SECONDS\n",
    "# values from the model documentation\n",
    "patch_padding = (0.025 / 2) / 0.01\n",
    "plt.xlim([-patch_padding-0.5, scores.shape[0] + patch_padding-0.5])\n",
    "# Label the top_N classes.\n",
    "yticks = range(0, top_n, 1)\n",
    "plt.yticks(yticks, [class_names[top_class_indices[x]] for x in yticks])\n",
    "_ = plt.ylim(-0.5 + np.array([top_n, 0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 筛选样本"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "划分train-set,val-set,test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data_frame, train_samples, val_samples):\n",
    "    train_dfs = []\n",
    "    val_dfs = []\n",
    "    test_dfs = []\n",
    "    for category, group in data_frame.groupby(\"category\"):\n",
    "        train_df = group.sample(n=train_samples)\n",
    "        group = group.drop(train_df.index)\n",
    "        val_df = group.sample(n=val_samples)\n",
    "        group = group.drop(val_df.index)\n",
    "        test_df = group\n",
    "        train_dfs.append(train_df)\n",
    "        val_dfs.append(val_df)\n",
    "        test_dfs.append(test_df)\n",
    "    train_df = pd.concat(train_dfs)\n",
    "    val_df = pd.concat(val_dfs)\n",
    "    test_df = pd.concat(test_dfs)\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编码，产生掩蔽，对label编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, root_dir, data_frame, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.data_frame = data_frame\n",
    "\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.label_encoder.fit(self.data_frame[\"category\"])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = os.path.join(self.root_dir, self.data_frame.iloc[idx][\"filename\"])\n",
    "        label = self.data_frame.iloc[idx][\"category\"]\n",
    "\n",
    "        # Load audio data and perform any desired transformations\n",
    "        sig, sr = librosa.load(audio_path, sr=16000, mono=True)\n",
    "        sig_t = torch.tensor(sig)\n",
    "        padding_mask = torch.zeros(1, sig_t.shape[0]).bool().squeeze(0)\n",
    "        if self.transform:\n",
    "            sig_t = self.transform(sig_t)\n",
    "\n",
    "        # Encode label as integer\n",
    "        label = self.label_encoder.transform([label])[0]\n",
    "\n",
    "        return sig_t, padding_mask, label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 继承LightningDataModule，产生trainset和valset的dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECS50DataModule(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_dir: str = \"/data/ESC-50-master/audio/\",\n",
    "        csv_file: str = \"/data/ESC-50-master/meta/esc50.csv\",\n",
    "        batch_size: int = 8,\n",
    "        split_ratio=0.8,\n",
    "        transform=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.root_dir = root_dir\n",
    "        self.csv_file = csv_file\n",
    "        self.batch_size = batch_size\n",
    "        self.split_ratio = split_ratio\n",
    "        self.transform = transform\n",
    "\n",
    "        self.setup()\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        data_frame = pd.read_csv(self.csv_file)\n",
    "        data_frame = data_frame.sample(frac=1).reset_index(\n",
    "            drop=True\n",
    "        )  # shuffle the data frame\n",
    "        split_index = int(len(data_frame) * self.split_ratio)\n",
    "        self.train_set = data_frame.iloc[:split_index, :]\n",
    "        self.val_set = data_frame.iloc[split_index:, :]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_df = AudioDataset(\n",
    "            root_dir=self.root_dir, data_frame=self.train_set, transform=self.transform\n",
    "        )\n",
    "\n",
    "        return DataLoader(train_df, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_df = AudioDataset(\n",
    "            root_dir=self.root_dir, data_frame=self.val_set, transform=self.transform\n",
    "        )\n",
    "\n",
    "        return DataLoader(val_df, batch_size=self.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "import sys\n",
    "def logger_init(log_level=logging.INFO,\n",
    "                log_dir='./ResultFile/',\n",
    "                ):\n",
    "    # 指定路径\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "  \n",
    "    log_path = os.path.join(log_dir, '_' + str(datetime.now())[:10] + '.txt')\n",
    "    formatter = '[%(asctime)s] - %(levelname)s: %(message)s'\n",
    "    logging.basicConfig(level=log_level,\n",
    "                        format=formatter,\n",
    "                        datefmt='%Y-%d-%m %H:%M:%S',\n",
    "                        handlers=[logging.FileHandler(log_path),\n",
    "                                logging.StreamHandler(sys.stdout)]\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader_row(file_name,row_num):\n",
    "    with open(file_name, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        row=list(reader)\n",
    "    return row[row_num]\n",
    "\n",
    "def csv_reader_cl(file_name,clo_num):\n",
    "    with open(file_name, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        column = [row[clo_num] for row in reader]\n",
    "    return column\n",
    "\n",
    "import csv\n",
    "csv_path=\"E:\\\\Shilong\\\\murmur\\\\dataset_all\\\\training_data.csv\"\n",
    "# csv_path=\"E:\\\\Shilong\\\\murmur\\\\circor_digiscope_dataset\\\\training_data.csv\"\n",
    "\n",
    "# get dataset tag from table\n",
    "row_line=csv_reader_row(csv_path,0)\n",
    "tag_list=list()\n",
    "# get index for 'Patient ID' and 'Outcome'\n",
    "tag_list.append(row_line.index('Patient ID'))\n",
    "tag_list.append(row_line.index('Murmur'))\n",
    "tag_list.append(row_line.index('Murmur locations'))\n",
    "tag_list.append(row_line.index('Systolic murmur timing'))\n",
    "tag_list.append(row_line.index('Diastolic murmur timing'))\n",
    "# for tag_index in tag_list:\n",
    "id_data=csv_reader_cl(csv_path,tag_list[0])\n",
    "Murmur=csv_reader_cl(csv_path,tag_list[1])\n",
    "Murmur_locations=csv_reader_cl(csv_path,tag_list[2])\n",
    "Systolic_murmur_timing=csv_reader_cl(csv_path,tag_list[3])\n",
    "Diastolic_murmur_timing=csv_reader_cl(csv_path,tag_list[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absent_id  = [out for out,Murmur in enumerate(Murmur) if Murmur=='Absent']\n",
    "present_id = [out for out,Murmur in enumerate(Murmur) if Murmur=='Present']\n",
    "# print(dict(enumerate(id_data[1:])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def index_load(tsvname):\n",
    "    \"\"\"读取tsv文件内容,不需要close函数\"\"\"\n",
    "    with open(tsvname, 'r') as f:\n",
    "        txt_data = f.read()\n",
    "    head=['start','end','period']\n",
    "    data=txt_data.split('\\n')[:-1]\n",
    "    #遍历每一行\n",
    "    for l in data:\n",
    "        sgmt=l.split('\\t')\n",
    "        if sgmt[2]!='0':\n",
    "            head=np.vstack([head,sgmt])\n",
    "    return head[1:]\n",
    "\n",
    "def state_div(tsvname,wavname,state_path,index):\n",
    "    index_file=index_load(tsvname)\n",
    "    recording, fs = librosa.load(wavname,sr=4000)\n",
    "    num=0\n",
    "    start_index2=0\n",
    "    end_index2=0\n",
    "    start_index4=0\n",
    "    end_index4=0\n",
    "\n",
    "    for i in range(index_file.shape[0]-3):\n",
    "        if index_file[i][2]=='2'and index_file[i+2][2]=='4':\n",
    "            start_index2=float(index_file[i][0])*fs\n",
    "            end_index2=float(index_file[i][1])*fs\n",
    "            start_index4=float(index_file[i+2][0])*fs\n",
    "            end_index4=float(index_file[i+2][1])*fs\n",
    "            num=num+1\n",
    "            #  解决出现_0.wav的问题\n",
    "            print(start_index2,end_index2,start_index4,end_index4)            \n",
    "            print(\"=============================================\")\n",
    "            print(\"wav name: \"+wavname)        \n",
    "            buff2 = recording[int(start_index2) :int(end_index2) ]  # 字符串索引切割\n",
    "            buff4 = recording[int(start_index4) :int(end_index4) ]  # 字符串索引切割\n",
    "            print(\"buff2 len: \"+str(len(buff2)),\"buff4 len: \"+str(len(buff4)))\n",
    "            # soundfile.write(state_path+\"{}_{}_{}.wav\".format(index,'Systolic' ,num),buff2,fs)\n",
    "            # soundfile.write(state_path+\"{}_{}_{}.wav\".format(index,'Diastolic',num),buff4,fs)\n",
    "\n",
    "def period_div(path,murmur,patient_id_list,positoin):\n",
    "    for mur in murmur:\n",
    "        for patient_id in patient_id_list:\n",
    "            for pos in positoin:\n",
    "                dir_path=path+mur+patient_id+\"\\\\\"+patient_id+pos\n",
    "                tsv_path=dir_path+\".tsv\"\n",
    "                wav_path=dir_path+\".wav\"\n",
    "                if os.path.exists(tsv_path):\n",
    "                    state_div(tsv_path,wav_path,dir_path+\"\\\\\",patient_id+pos)\n",
    "\n",
    "def get_patientid(csv_path):\n",
    "    # 'import csv' is required\n",
    "    with open(csv_path) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        id = [row[0] for row in reader]   # weight 同列的数据\n",
    "    return id\n",
    "\n",
    "murmur=[\"Absent\\\\\",\"Present\\\\\"]\n",
    "positoin=['_AV','_MV','_PV','_TV']\n",
    "folder_path=r'E:\\Shilong\\murmur\\03_circor_states\\\\'\n",
    "absent_csv_path=r'E:\\Shilong\\murmur\\03_Classifier\\LM\\BEATs\\absent_id.csv'\n",
    "absent_patient_id=get_patientid(absent_csv_path)\n",
    "period_div(folder_path,murmur,absent_patient_id,positoin)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio.compliance.kaldi as ta_kaldi\n",
    "import torch\n",
    "\n",
    "waveform = torch.randn(1, 2800)\n",
    "fbank = ta_kaldi.fbank(waveform, num_mel_bins=128, sample_frequency=16000, frame_length=25, frame_shift=10)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_len(dir_path,csv_path,Murmur:str,id_data,Murmur_locations):\n",
    "    slen=[]\n",
    "    dlen=[]\n",
    "    # label=[]\n",
    "    if not os.path.exists(csv_path):\n",
    "        os.makedirs(csv_path)\n",
    "\n",
    "    for root,dir,file in os.walk(dir_path):\n",
    "        for subfile in file:\n",
    "            wav_path=os.path.join(root,subfile)            \n",
    "            if os.path.exists(wav_path):\n",
    "                # 数据读取\n",
    "                print(\"reading: \"+subfile)\n",
    "                y, sr = librosa.load(wav_path, sr=4000)\n",
    "                y_16k = librosa.resample(y=y, orig_sr=sr, target_sr=16000)\n",
    "                print(\"y_16k size: \"+str(y_16k.size))\n",
    "                if subfile.split('_')[2] == 'Systolic':\n",
    "                    slen.append(y_16k.size)\n",
    "                else:\n",
    "                    dlen.append(y_16k.size)    \n",
    "    return np.array(slen),np.array(dlen)\n",
    "\n",
    "slen,dlen=cal_len(absent_train_path,absent_train_csv_path,'Absent',id_data,Murmur_locations)# absent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=torch.int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "a=np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "b=torch.tensor(a)\n",
    "b\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_Shilong",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
