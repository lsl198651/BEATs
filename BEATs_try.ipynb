{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数冻结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "# 加载预训练的模型\n",
    "model = models.resnet50(pretrained=True)\n",
    "\n",
    "# 冻结模型的部分权重\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 替换或添加自定义的全连接层\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 10)  # 假设目标任务是10分类\n",
    "\n",
    "# 指定需要训练的参数\n",
    "trainable_params = model.fc.parameters()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(trainable_params, lr=0.001, momentum=0.9)\n",
    "\n",
    "# 在训练循环中只更新需要训练的参数\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存训练日志文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_log_filename = \"train_log.txt\"\n",
    "train_log_filepath = os.path.join(result_dir, train_log_filename)\n",
    "train_log_txt_formatter = \"{time_str} [Epoch] {epoch:03d} [Loss] {loss_str}\\n\"\n",
    "to_write=train_log_txt_formatter.format(time_str=time.strtime(%Y_%n_%d_%H:%M:%S),\n",
    "                                        epoch=epoch,\n",
    "                                        loss_str=\" \".join([\"{}\".format(loss)]))\n",
    "with open(train_log_filepath,\"a\") as f:\n",
    "    f.write(to_write)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load NPY文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "loadData = np.load(r'E:\\Shilong\\murmur\\03_Classifier\\test_features.npy')\n",
    "\n",
    "print(\"----type----\")\n",
    "print(type(loadData))\n",
    "print(\"----shape----\")\n",
    "print(loadData.shape)\n",
    "print(\"----data----\")\n",
    "print(loadData)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 绘制混淆矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "def draw_confusion_matrix(label_true, label_pred, label_name, normlize, title=\"Confusion Matrix\", pdf_save_path=None, dpi=100):\n",
    "    \"\"\"\n",
    "\n",
    "    @param label_true: 真实标签，比如[0,1,2,7,4,5,...]\n",
    "    @param label_pred: 预测标签，比如[0,5,4,2,1,4,...]\n",
    "    @param label_name: 标签名字，比如['cat','dog','flower',...]\n",
    "    @param normlize: 是否设元素为百分比形式\n",
    "    @param title: 图标题\n",
    "    @param pdf_save_path: 是否保存，是则为保存路径pdf_save_path=xxx.png | xxx.pdf | ...等其他plt.savefig支持的保存格式\n",
    "    @param dpi: 保存到文件的分辨率，论文一般要求至少300dpi\n",
    "    @return:\n",
    "\n",
    "    example：\n",
    "            draw_confusion_matrix(label_true=y_gt,\n",
    "                          label_pred=y_pred,\n",
    "                          label_name=[\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"],\n",
    "                          normlize=True,\n",
    "                          title=\"Confusion Matrix on Fer2013\",\n",
    "                          pdf_save_path=\"Confusion_Matrix_on_Fer2013.png\",\n",
    "                          dpi=300)\n",
    "\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(label_true, label_pred)\n",
    "    if normlize:\n",
    "        row_sums = np.sum(cm, axis=1)  # 计算每行的和\n",
    "        cm = cm / row_sums[:, np.newaxis]  # 广播计算每个元素占比\n",
    "    cm=cm.T\n",
    "    plt.imshow(cm, cmap='Blues')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predict label\")\n",
    "    plt.ylabel(\"Truth label\")\n",
    "    plt.yticks(range(label_name.__len__()), label_name)\n",
    "    plt.xticks(range(label_name.__len__()), label_name, rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.colorbar()\n",
    "\n",
    "    for i in range(label_name.__len__()):\n",
    "        for j in range(label_name.__len__()):\n",
    "            color = (1, 1, 1) if i == j else (0, 0, 0)\t# 对角线字体白色，其他黑色\n",
    "            value = float(format('%.2f' % cm[i, j]))\n",
    "            plt.text(i, j, value, verticalalignment='center', horizontalalignment='center', color=color)\n",
    "\n",
    "    # plt.show()\n",
    "    if not pdf_save_path is None:\n",
    "        plt.savefig(pdf_save_path, bbox_inches='tight',dpi=dpi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_name=['angry', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "\n",
    "y_gt=[]\n",
    "y_pred=[]\n",
    "for index, (labels, imgs) in enumerate(test_loader):\n",
    "    labels_pd = model(imgs)\n",
    "    predict_np = np.argmax(labels_pd.cpu().detach().numpy(), axis=-1)   # array([0,5,1,6,3,...],dtype=int64)\n",
    "    labels_np = labels.numpy()                                          # array([0,5,0,6,2,...],dtype=int64)\n",
    "\t\n",
    "    y_pred.append(labels_np)\n",
    "    y_gt.append(labels_np)\n",
    "    \n",
    "draw_confusion_matrix(label_true=y_gt,\t\t\t# y_gt=[0,5,1,6,3,...]\n",
    "                      label_pred=y_pred,\t    # y_pred=[0,5,1,6,3,...]\n",
    "                      label_name=[\"An\", \"Di\", \"Fe\", \"Ha\", \"Sa\", \"Su\", \"Ne\"],\n",
    "                      normlize=True,\n",
    "                      title=\"Confusion Matrix on Fer2013\",\n",
    "                      pdf_save_path=\"Confusion_Matrix_on_Fer2013.jpg\",\n",
    "                      dpi=300)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 召回率计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "pred = [0, 1, 0, 1] # 预测的值\n",
    "target = [0, 1, 1, 0] # 真实的值\n",
    "\n",
    "r = recall_score(pred, target)\n",
    "\n",
    "print(r)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果不是 0 1 的值，是其他二分类的值，那么就可以通过 labels、pos_label 来指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [3,4]  # 二分类 两个类别的值\n",
    "\n",
    "pred = [3, 4, 3, 4] # 预测的值\n",
    "\n",
    "target = [3, 4, 4, 3] # 真实的值\n",
    "\n",
    "r = recall_score(pred, target , labels = labels , pos_label= 3) # pos_label指定正样本的值是多少\n",
    "\n",
    "print(r)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化\n",
    "YAMNet 还会返回一些可用于可视化的附加信息。我们看一下波形、声谱图和推断的热门类。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the waveform.\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(waveform)\n",
    "plt.xlim([0, len(waveform)])\n",
    "\n",
    "# Plot the log-mel spectrogram (returned by the model).\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.imshow(spectrogram_np.T, aspect='auto', interpolation='nearest', origin='lower')\n",
    "\n",
    "# Plot and label the model output scores for the top-scoring classes.\n",
    "mean_scores = np.mean(scores, axis=0)\n",
    "top_n = 10\n",
    "top_class_indices = np.argsort(mean_scores)[::-1][:top_n]\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.imshow(scores_np[:, top_class_indices].T, aspect='auto', interpolation='nearest', cmap='gray_r')\n",
    "\n",
    "# patch_padding = (PATCH_WINDOW_SECONDS / 2) / PATCH_HOP_SECONDS\n",
    "# values from the model documentation\n",
    "patch_padding = (0.025 / 2) / 0.01\n",
    "plt.xlim([-patch_padding-0.5, scores.shape[0] + patch_padding-0.5])\n",
    "# Label the top_N classes.\n",
    "yticks = range(0, top_n, 1)\n",
    "plt.yticks(yticks, [class_names[top_class_indices[x]] for x in yticks])\n",
    "_ = plt.ylim(-0.5 + np.array([top_n, 0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 筛选样本"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "划分train-set,val-set,test-set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data_frame, train_samples, val_samples):\n",
    "    train_dfs = []\n",
    "    val_dfs = []\n",
    "    test_dfs = []\n",
    "    for category, group in data_frame.groupby(\"category\"):\n",
    "        train_df = group.sample(n=train_samples)\n",
    "        group = group.drop(train_df.index)\n",
    "        val_df = group.sample(n=val_samples)\n",
    "        group = group.drop(val_df.index)\n",
    "        test_df = group\n",
    "        train_dfs.append(train_df)\n",
    "        val_dfs.append(val_df)\n",
    "        test_dfs.append(test_df)\n",
    "    train_df = pd.concat(train_dfs)\n",
    "    val_df = pd.concat(val_dfs)\n",
    "    test_df = pd.concat(test_dfs)\n",
    "    return train_df, val_df, test_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编码，产生掩蔽，对label编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, root_dir, data_frame, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.data_frame = data_frame\n",
    "\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.label_encoder.fit(self.data_frame[\"category\"])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        audio_path = os.path.join(self.root_dir, self.data_frame.iloc[idx][\"filename\"])\n",
    "        label = self.data_frame.iloc[idx][\"category\"]\n",
    "\n",
    "        # Load audio data and perform any desired transformations\n",
    "        sig, sr = librosa.load(audio_path, sr=16000, mono=True)\n",
    "        sig_t = torch.tensor(sig)\n",
    "        padding_mask = torch.zeros(1, sig_t.shape[0]).bool().squeeze(0)\n",
    "        if self.transform:\n",
    "            sig_t = self.transform(sig_t)\n",
    "\n",
    "        # Encode label as integer\n",
    "        label = self.label_encoder.transform([label])[0]\n",
    "\n",
    "        return sig_t, padding_mask, label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 继承LightningDataModule，产生trainset和valset的dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECS50DataModule(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root_dir: str = \"/data/ESC-50-master/audio/\",\n",
    "        csv_file: str = \"/data/ESC-50-master/meta/esc50.csv\",\n",
    "        batch_size: int = 8,\n",
    "        split_ratio=0.8,\n",
    "        transform=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        super().__init__(**kwargs)\n",
    "        self.root_dir = root_dir\n",
    "        self.csv_file = csv_file\n",
    "        self.batch_size = batch_size\n",
    "        self.split_ratio = split_ratio\n",
    "        self.transform = transform\n",
    "\n",
    "        self.setup()\n",
    "\n",
    "    def prepare_data(self):\n",
    "        pass\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        data_frame = pd.read_csv(self.csv_file)\n",
    "        data_frame = data_frame.sample(frac=1).reset_names(\n",
    "            drop=True\n",
    "        )  # shuffle the data frame\n",
    "        split_names = int(len(data_frame) * self.split_ratio)\n",
    "        self.train_set = data_frame.iloc[:split_names, :]\n",
    "        self.val_set = data_frame.iloc[split_names:, :]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_df = AudioDataset(\n",
    "            root_dir=self.root_dir, data_frame=self.train_set, transform=self.transform\n",
    "        )\n",
    "\n",
    "        return DataLoader(train_df, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_df = AudioDataset(\n",
    "            root_dir=self.root_dir, data_frame=self.val_set, transform=self.transform\n",
    "        )\n",
    "\n",
    "        return DataLoader(val_df, batch_size=self.batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from datetime import datetime\n",
    "import sys\n",
    "def logger_init(log_level=logging.INFO,\n",
    "                log_dir='./ResultFile/',\n",
    "                ):\n",
    "    # 指定路径\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "  \n",
    "    log_path = os.path.join(log_dir, '_' + str(datetime.now())[:10] + '.txt')\n",
    "    formatter = '[%(asctime)s] - %(levelname)s: %(message)s'\n",
    "    logging.basicConfig(level=log_level,\n",
    "                        format=formatter,\n",
    "                        datefmt='%Y-%d-%m %H:%M:%S',\n",
    "                        handlers=[logging.FileHandler(log_path),\n",
    "                                logging.StreamHandler(sys.stdout)]\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader_row(file_name,row_num):\n",
    "    with open(file_name, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        row=list(reader)\n",
    "    return row[row_num]\n",
    "\n",
    "def csv_reader_cl(file_name,clo_num):\n",
    "    with open(file_name, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        column = [row[clo_num] for row in reader]\n",
    "    return column\n",
    "\n",
    "import csv\n",
    "csv_path=\"E:\\\\Shilong\\\\murmur\\\\dataset_all\\\\training_data.csv\"\n",
    "# csv_path=\"E:\\\\Shilong\\\\murmur\\\\circor_digiscope_dataset\\\\training_data.csv\"\n",
    "\n",
    "# get dataset tag from table\n",
    "row_line=csv_reader_row(csv_path,0)\n",
    "tag_list=list()\n",
    "# get names for 'Patient ID' and 'Outcome'\n",
    "tag_list.append(row_line.names('Patient ID'))\n",
    "tag_list.append(row_line.names('Murmur'))\n",
    "tag_list.append(row_line.names('Murmur locations'))\n",
    "tag_list.append(row_line.index('Systolic murmur timing'))\n",
    "tag_list.append(row_line.index('Diastolic murmur timing'))\n",
    "# for tag_names in tag_list:\n",
    "id_data=csv_reader_cl(csv_path,tag_list[0])\n",
    "Murmur=csv_reader_cl(csv_path,tag_list[1])\n",
    "Murmur_locations=csv_reader_cl(csv_path,tag_list[2])\n",
    "Systolic_murmur_timing=csv_reader_cl(csv_path,tag_list[3])\n",
    "Diastolic_murmur_timing=csv_reader_cl(csv_path,tag_list[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absent_id  = [out for out,Murmur in enumerate(Murmur) if Murmur=='Absent']\n",
    "present_id = [out for out,Murmur in enumerate(Murmur) if Murmur=='Present']\n",
    "# print(dict(enumerate(id_data[1:])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def index_load(tsvname):\n",
    "    \"\"\"读取tsv文件内容,不需要close函数\"\"\"\n",
    "    with open(tsvname, 'r') as f:\n",
    "        txt_data = f.read()\n",
    "    head=['start','end','period']\n",
    "    data=txt_data.split('\\n')[:-1]\n",
    "    #遍历每一行\n",
    "    for l in data:\n",
    "        sgmt=l.split('\\t')\n",
    "        if sgmt[2]!='0':\n",
    "            head=np.vstack([head,sgmt])\n",
    "    return head[1:]\n",
    "\n",
    "def state_div(tsvname,wavname,state_path,index):\n",
    "    index_file=index_load(tsvname)\n",
    "    recording, fs = librosa.load(wavname,sr=4000)\n",
    "    num=0\n",
    "    start_index2=0\n",
    "    end_index2=0\n",
    "    start_index4=0\n",
    "    end_index4=0\n",
    "\n",
    "    for i in range(index_file.shape[0]-3):\n",
    "        if index_file[i][2]=='2'and index_file[i+2][2]=='4':\n",
    "            start_index2=float(index_file[i][0])*fs\n",
    "            end_index2=float(index_file[i][1])*fs\n",
    "            start_index4=float(index_file[i+2][0])*fs\n",
    "            end_index4=float(index_file[i+2][1])*fs\n",
    "            num=num+1\n",
    "            #  解决出现_0.wav的问题\n",
    "            print(start_index2,end_index2,start_index4,end_index4)            \n",
    "            print(\"=============================================\")\n",
    "            print(\"wav name: \"+wavname)        \n",
    "            buff2 = recording[int(start_index2) :int(end_index2) ]  # 字符串索引切割\n",
    "            buff4 = recording[int(start_index4) :int(end_index4) ]  # 字符串索引切割\n",
    "            print(\"buff2 len: \"+str(len(buff2)),\"buff4 len: \"+str(len(buff4)))\n",
    "            # soundfile.write(state_path+\"{}_{}_{}.wav\".format(index,'Systolic' ,num),buff2,fs)\n",
    "            # soundfile.write(state_path+\"{}_{}_{}.wav\".format(index,'Diastolic',num),buff4,fs)\n",
    "\n",
    "def period_div(path,murmur,patient_id_list,positoin):\n",
    "    for mur in murmur:\n",
    "        for patient_id in patient_id_list:\n",
    "            for pos in positoin:\n",
    "                dir_path=path+mur+patient_id+\"\\\\\"+patient_id+pos\n",
    "                tsv_path=dir_path+\".tsv\"\n",
    "                wav_path=dir_path+\".wav\"\n",
    "                if os.path.exists(tsv_path):\n",
    "                    state_div(tsv_path,wav_path,dir_path+\"\\\\\",patient_id+pos)\n",
    "\n",
    "def get_patientid(csv_path):\n",
    "    # 'import csv' is required\n",
    "    with open(csv_path) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        id = [row[0] for row in reader]   # weight 同列的数据\n",
    "    return id\n",
    "\n",
    "murmur=[\"Absent\\\\\",\"Present\\\\\"]\n",
    "positoin=['_AV','_MV','_PV','_TV']\n",
    "folder_path=r'E:\\Shilong\\murmur\\03_circor_states\\\\'\n",
    "absent_csv_path=r'E:\\Shilong\\murmur\\03_Classifier\\LM\\BEATs\\absent_id.csv'\n",
    "absent_patient_id=get_patientid(absent_csv_path)\n",
    "period_div(folder_path,murmur,absent_patient_id,positoin)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio.compliance.kaldi as ta_kaldi\n",
    "import torch\n",
    "\n",
    "waveform = torch.randn(1, 2800)\n",
    "fbank = ta_kaldi.fbank(waveform, num_mel_bins=128, sample_frequency=16000, frame_length=25, frame_shift=10)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_len(dir_path,csv_path,Murmur:str,id_data,Murmur_locations):\n",
    "    slen=[]\n",
    "    dlen=[]\n",
    "    # label=[]\n",
    "    if not os.path.exists(csv_path):\n",
    "        os.makedirs(csv_path)\n",
    "\n",
    "    for root,dir,file in os.walk(dir_path):\n",
    "        for subfile in file:\n",
    "            wav_path=os.path.join(root,subfile)            \n",
    "            if os.path.exists(wav_path):\n",
    "                # 数据读取\n",
    "                print(\"reading: \"+subfile)\n",
    "                y, sr = librosa.load(wav_path, sr=4000)\n",
    "                y_16k = librosa.resample(y=y, orig_sr=sr, target_sr=16000)\n",
    "                print(\"y_16k size: \"+str(y_16k.size))\n",
    "                if subfile.split('_')[2] == 'Systolic':\n",
    "                    slen.append(y_16k.size)\n",
    "                else:\n",
    "                    dlen.append(y_16k.size)    \n",
    "    return np.array(slen),np.array(dlen)\n",
    "\n",
    "slen,dlen=cal_len(absent_train_path,absent_train_csv_path,'Absent',id_data,Murmur_locations)# absent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "a=np.array([1,2,3,4,5,6,7,8,9,10])\n",
    "b=torch.tensor(a)\n",
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absent_train_csv_path = r'D:\\Shilong\\murmur\\03_circor_states\\train_csv'\n",
    "absent_test_csv_path = r'D:\\Shilong\\murmur\\03_circor_states\\test_csv'\n",
    "present_train_csv_path = r'D:\\Shilong\\murmur\\03_circor_states\\train_csv'\n",
    "present_test_csv_path = r'D:\\Shilong\\murmur\\03_circor_states\\test_csv'\n",
    "\n",
    "filepath=r'D:\\Shilong\\murmur\\03_circor_states'\n",
    "absent_train_path=r'D:\\Shilong\\murmur\\03_circor_states\\train\\Absent'\n",
    "absent_test_path=r'D:\\Shilong\\murmur\\03_circor_states\\test\\Absent'\n",
    "present_train_path=r'D:\\Shilong\\murmur\\03_circor_states\\train\\Present'\n",
    "present_test_path=r'D:\\Shilong\\murmur\\03_circor_states\\test\\Present'\n",
    "\n",
    "atslen,atdlen=cal_len(absent_train_path,absent_train_csv_path,'Absent',id_data,Murmur_locations)# absent\n",
    "avslen,avdlen=cal_len(absent_test_path,absent_test_csv_path,'Absent',id_data,Murmur_locations)# absent\n",
    "ptslen,ptdlen=cal_len(present_train_path,present_train_csv_path,'Present',id_data,Murmur_locations)# absent\n",
    "pvslen,pvdlen=cal_len(present_test_path,present_test_csv_path,'Present',id_data,Murmur_locations)# absent\n",
    "\n",
    "atslen_path=r'D:\\Shilong\\murmur\\03_circor_states\\atslen.csv'\n",
    "atdlen_path=r'D:\\Shilong\\murmur\\03_circor_states\\atdlen.csv'\n",
    "avslen_path=r'D:\\Shilong\\murmur\\03_circor_states\\avslen.csv'\n",
    "avdlen_path=r'D:\\Shilong\\murmur\\03_circor_states\\avdlen.csv'\n",
    "ptslen_path=r'D:\\Shilong\\murmur\\03_circor_states\\ptslen.csv'\n",
    "ptdlen_path=r'D:\\Shilong\\murmur\\03_circor_states\\ptdlen.csv'\n",
    "pvslen_path=r'D:\\Shilong\\murmur\\03_circor_states\\pvslen.csv'\n",
    "pvdlen_path=r'D:\\Shilong\\murmur\\03_circor_states\\pvdlen.csv'\n",
    "\n",
    "pd.DataFrame(atslen).to_csv(atslen_path, index=False, header=False)\n",
    "pd.DataFrame(atdlen).to_csv(atdlen_path, index=False, header=False)\n",
    "pd.DataFrame(avslen).to_csv(avslen_path, index=False, header=False)\n",
    "pd.DataFrame(avdlen).to_csv(avdlen_path, index=False, header=False)\n",
    "pd.DataFrame(ptslen).to_csv(ptslen_path, index=False, header=False)\n",
    "pd.DataFrame(ptdlen).to_csv(ptdlen_path, index=False, header=False)\n",
    "pd.DataFrame(pvslen).to_csv(pvslen_path, index=False, header=False)\n",
    "pd.DataFrame(pvdlen).to_csv(pvdlen_path, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "absent_1=0\n",
    "persent_1=0\n",
    "absent_2=0\n",
    "persent_2=0\n",
    "\n",
    "\n",
    "file_path_train=r'D:\\Shilong\\murmur\\03_circor_states\\train'\n",
    "file_path_test=r'D:\\Shilong\\murmur\\03_circor_states\\test'\n",
    "target_dir_train_a=r'D:\\Shilong\\murmur\\03_circor_states\\trainset\\absent'\n",
    "target_dir_train_p=r'D:\\Shilong\\murmur\\03_circor_states\\trainset\\present'\n",
    "target_dir_test_a=r'D:\\Shilong\\murmur\\03_circor_states\\testset\\absent'\n",
    "target_dir_test_p=r'D:\\Shilong\\murmur\\03_circor_states\\testset\\present'\n",
    "\n",
    "for root,dir,file in os.walk(file_path_train):\n",
    "    for subfile in file:\n",
    "        files=os.path.join(root,subfile)\n",
    "        print(subfile)\n",
    "        state=subfile.split(\"_\")[4]        \n",
    "        if state=='Absent':\n",
    "            shutil.copy(files, target_dir_train_a + \"\\\\\")\n",
    "        if state=='Present':\n",
    "            shutil.copy(files, target_dir_train_p + \"\\\\\")\n",
    "\n",
    "for root,dir,file in os.walk(file_path_test):\n",
    "    for subfile in file:\n",
    "        files=os.path.join(root,subfile)\n",
    "        print(subfile)\n",
    "        state=subfile.split(\"_\")[4]        \n",
    "        if state=='Absent':\n",
    "            shutil.copy(files, target_dir_test_a + \"\\\\\")\n",
    "        if state=='Present':\n",
    "            shutil.copy(files, target_dir_test_p + \"\\\\\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Audio data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speed tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speed_rate = np.random.uniform(0.7,1.3)\n",
    "wav_speed_tune = cv2.resize(wav, (1, int(len(wav) * speed_rate))).squeeze()\n",
    "print('speed rate: %.3f' % speed_rate, '(lower is faster)')\n",
    "if len(wav_speed_tune) < 16000:\n",
    "    pad_len = 16000 - len(wav_speed_tune)\n",
    "    wav_speed_tune = np.r_[np.random.uniform(-0.001,0.001,int(pad_len/2)),\n",
    "                           wav_speed_tune,\n",
    "                           np.random.uniform(-0.001,0.001,int(np.ceil(pad_len/2)))]\n",
    "else: \n",
    "    cut_len = len(wav_speed_tune) - 16000\n",
    "    wav_speed_tune = wav_speed_tune[int(cut_len/2):int(cut_len/2)+16000]\n",
    "print('wav length: ', wav_speed_tune.shape[0])\n",
    "ipd.Audio(wav_speed_tune, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mix background noise & volume tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bg_files = os.listdir('../input/train/audio/_background_noise_/')\n",
    "bg_files.remove('README.md')\n",
    "chosen_bg_file = bg_files[np.random.randint(6)]\n",
    "bg, sr = librosa.load('../input/train/audio/_background_noise_/'+chosen_bg_file, sr=None)\n",
    "print(chosen_bg_file,'|', bg.shape[0], bg.max(), bg.min())\n",
    "ipd.Audio(bg, rate=sr) # !! be prepared when playing the noise, bacause it's so ANNOYING !!\n",
    "\n",
    "start_ = np.random.randint(bg.shape[0]-16000)\n",
    "bg_slice = bg[start_ : start_+16000]\n",
    "wav_with_bg = wav * np.random.uniform(0.8, 1.2) + \\\n",
    "              bg_slice * np.random.uniform(0, 0.1)\n",
    "ipd.Audio(wav_with_bg, rate=sr) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stretching the sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import soundfile\n",
    "def stretch(data, rates):   \n",
    "    data = librosa.effects.time_stretch(data, rate=rates)\n",
    "    return data\n",
    "    \n",
    "\n",
    "def get_spectrogram(wav):\n",
    "    D = librosa.stft(wav, n_fft=480, hop_length=160,\n",
    "                     win_length=480, window='hamming')\n",
    "    spect, phase = librosa.magphase(D)\n",
    "    return spect\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    data,sr=librosa.load(r'D:\\Shilong\\murmur\\03_circor_states\\Absent\\2530\\2530_AV\\.wav', sr=4000)\n",
    "    data_stretch =stretch(data, 2)\n",
    "\n",
    "\n",
    "    data_stretch_log_spect = 20*np.log10(get_spectrogram(data_stretch))\n",
    "    data_log_spect = np.log(get_spectrogram(data))\n",
    "    # soundfile.write(r\"D:\\Shilong\\murmur\\03_circor_states\\Absent\\2530\\2530AV.wav\",\n",
    "    #             data,\n",
    "    #             sr*2,\n",
    "    #         )\n",
    "    soundfile.write(r\"D:\\Shilong\\murmur\\03_circor_states\\Absent\\2530_AV.wav\",\n",
    "    data_stretch,\n",
    "    sr,\n",
    "            )\n",
    "\n",
    "   \n",
    "    plt.title('spectrogram of origin audio and stretch audio')\n",
    "    plt.subplot(2, 1, 1)   \n",
    "    plt.imshow(data_log_spect, aspect='auto', origin='lower',)    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.imshow(data_stretch_log_spect, aspect='auto', origin='lower',)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUDIO FEATURE AUGMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "print(torch.__version__)\n",
    "print(torchaudio.__version__)\n",
    "\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "wav_path = r'D:\\Shilong\\murmur\\03_circor_states\\trainset\\volume2\\9979_AV_Systolic_1_Present_Holosystolic.wav_volume2.wav'\n",
    "wav_path2 = r'D:\\Shilong\\murmur\\03_circor_states\\trainset\\present\\9979_AV_Systolic_1_Present_Holosystolic.wav'\n",
    "def get_spectrogram(\n",
    "    n_fft=400,\n",
    "    win_len=None,\n",
    "    hop_len=None,\n",
    "    power=2.0,\n",
    "    path=wav_path,\n",
    "):\n",
    "    waveform, _ = torchaudio.load(path)\n",
    "    waveform = torchaudio.transforms.Resample(4000, 16000)(waveform)\n",
    "    spectrogram = T.Spectrogram(\n",
    "        n_fft=n_fft,\n",
    "        win_length=win_len,\n",
    "        hop_length=hop_len,\n",
    "        center=True,\n",
    "        pad_mode=\"reflect\",\n",
    "        power=power,\n",
    "    )\n",
    "    melspec=T.MelSpectrogram(\n",
    "        sample_rate = 16000,\n",
    "        n_fft= 200,       \n",
    "        )\n",
    "    return melspec(waveform)\n",
    "\n",
    "\n",
    "\n",
    "def plot_spectrogram(spec, title=None, ylabel=\"freq_bin\", aspect=\"auto\", xmax=None):\n",
    "    fig, axs = plt.subplots(1, 1)\n",
    "    axs.set_title(title or \"Spectrogram (db)\")\n",
    "    axs.set_ylabel(ylabel)\n",
    "    axs.set_xlabel(\"frame\")\n",
    "    im = axs.imshow(librosa.power_to_db(spec), origin=\"lower\", aspect=aspect)\n",
    "    if xmax:\n",
    "        axs.set_xlim((0, xmax))\n",
    "    fig.colorbar(im, ax=axs)\n",
    "    plt.show(block=False)\n",
    "    \n",
    "# TimeStretch\n",
    "\n",
    "spec = get_spectrogram()\n",
    "spec2 = get_spectrogram(path=wav_path2)\n",
    "stretch = T.TimeStretch(n_freq = 128)\n",
    "\n",
    "\n",
    "rate = 1.2\n",
    "spec_ = stretch(spec, rate)\n",
    "\n",
    "plot_spectrogram(torch.abs(spec_[0]), title=f\"Stretched x{rate}\", aspect=\"equal\", xmax=18)\n",
    "\n",
    "plot_spectrogram(torch.abs(spec[0]), title=\"origin\", aspect=\"equal\", xmax=18)\n",
    "plot_spectrogram(torch.abs(spec2[0]), title=\"origin2\", aspect=\"equal\", xmax=18)\n",
    "rate = 0.8\n",
    "spec_ = stretch(spec, rate)\n",
    "plot_spectrogram(torch.abs(spec_[0]), title=f\"Stretched x{rate}\", aspect=\"equal\", xmax=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "from torchaudio.utils import download_asset\n",
    "\n",
    "SAMPLE_WAV_SPEECH_PATH = r\"D:\\Shilong\\murmur\\01_dataset\\04_newDataset\\Absent\\2530\\2530_AV.wav\"\n",
    "def get_spectrogram(\n",
    "    n_fft=400,\n",
    "    win_len=None,\n",
    "    hop_len=None,\n",
    "    power=2.0,\n",
    "):\n",
    "    waveform, _ = torchaudio.load(SAMPLE_WAV_SPEECH_PATH)\n",
    "    # waveform = torchaudio.transforms.Resample(4000, 16000)(waveform)\n",
    "    spectrogram = T.MelSpectrogram(\n",
    "        sample_rate=4000\n",
    "    )    \n",
    "    return waveform\n",
    "\n",
    "\n",
    "def plot_spectrogram(spec, title=None, ylabel=\"freq_bin\", aspect=\"auto\", xmax=None):\n",
    "    fig, axs = plt.subplots(1, 1)\n",
    "    # axs.set_title(title or \"Spectrogram (db)\")\n",
    "    # axs.set_ylabel(ylabel)\n",
    "    # axs.set_xlabel(\"frame\")\n",
    "    im = axs.imshow(librosa.power_to_db(spec), origin=\"lower\", aspect=aspect)\n",
    "    axs.axes.xaxis.set_visible(False)\n",
    "    axs.axes.yaxis.set_visible(False)\n",
    "    axs.spines['top'].set_visible(False)\n",
    "    axs.spines['right'].set_visible(False)\n",
    "    axs.spines['bottom'].set_visible(False)\n",
    "    axs.spines['left'].set_visible(False)\n",
    "\n",
    "    if xmax:\n",
    "        axs.set_xlim((0, xmax))\n",
    "    # fig.colorbar(im, ax=axs)\n",
    "    # plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)\n",
    "    # plt.margins(0, 0)\n",
    "    plt.show(block=False)\n",
    "\n",
    "spec = get_spectrogram(power=None)\n",
    "stretch = T.TimeStretch(n_freq=128)\n",
    "xmax=400\n",
    "plot_spectrogram(spec, title=\"mel\", aspect=\"equal\", xmax=xmax)\n",
    "\n",
    "# rate = 1.2\n",
    "# spec_ = stretch(spec, rate)\n",
    "# plot_spectrogram(torch.abs(spec_[0]), title=f\"Stretched x{rate}\", aspect=\"equal\", xmax=xmax)\n",
    "\n",
    "# rate = 0.9\n",
    "# spec_ = stretch(spec, rate)\n",
    "# plot_spectrogram(torch.abs(spec_[0]), title=f\"Stretched x{rate}\", aspect=\"equal\", xmax=xmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, sr = librosa.load(r\"D:\\Shilong\\murmur\\01_dataset\\04_newDataset\\Absent\\2530\\2530_AV.wav\", sr=4000)\n",
    "# samples = samples[6000:16000]\n",
    "\n",
    "# print(len(samples), sr)\n",
    "time = np.arange(0, len(samples)) * (1.0 / sr)\n",
    "\n",
    "axs=plt.plot(time, samples)\n",
    "axs.axes.xaxis.set_visible(False)\n",
    "axs.axes.yaxis.set_visible(False)\n",
    "axs.spines['top'].set_visible(False)\n",
    "axs.spines['right'].set_visible(False)\n",
    "axs.spines['bottom'].set_visible(False)\n",
    "axs.spines['left'].set_visible(False)\n",
    "\n",
    "# plt.savefig(\"your dir\\语音信号时域波形图\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wav mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchaudio\n",
    "from matplotlib import pyplot as plt\n",
    "import librosa\n",
    "# \\2530_AV_Diastolic_10_Absent_nan\n",
    "waveform, _ = torchaudio.load(r'D:\\Shilong\\murmur\\03_circor_states\\trainset\\present\\9979_AV_Systolic_1_Present_Holosystolic.wav')\n",
    "wavform=torchaudio.transforms.Resample(orig_freq=4000, new_freq=16000)(waveform)\n",
    "fbank = torchaudio.compliance.kaldi.fbank(\n",
    "                waveform,\n",
    "                num_mel_bins=128,\n",
    "                sample_frequency=16000,\n",
    "                frame_length=25,\n",
    "                frame_shift=10,\n",
    "            )\n",
    "freqm=1# 横向\n",
    "timem=1# 纵向\n",
    "freqm = torchaudio.transforms.FrequencyMasking(freqm)\n",
    "timem = torchaudio.transforms.TimeMasking(timem)\n",
    "fbank = torch.transpose(fbank, 0, 1)\n",
    "\n",
    "# NOTE this line, this is the trick, new torchaudio expect [1, freq, time] while old support [freq, time]\n",
    "# comment this line will lead to an issue.\n",
    "fbank = fbank.squeeze(0)\n",
    "print(fbank.shape)\n",
    "if freqm != 0:\n",
    "    fbank = freqm(fbank)\n",
    "if timem != 0:\n",
    "    fbank = timem(fbank)\n",
    "\n",
    "def plot_spectrogram(spec, title=None, ylabel=\"freq_bin\", aspect=\"auto\", xmax=None):\n",
    "    fig, axs = plt.subplots(1, 1)\n",
    "    axs.set_title(title or \"Spectrogram (db)\")\n",
    "    axs.set_ylabel(ylabel)\n",
    "    axs.set_xlabel(\"frame\")\n",
    "    im = axs.imshow(librosa.power_to_db(spec), origin=\"lower\", aspect=aspect)\n",
    "    if xmax:\n",
    "        axs.set_xlim((0, xmax))\n",
    "    fig.colorbar(im, ax=axs)\n",
    "    plt.show(block=False)\n",
    "\n",
    "plot_spectrogram(fbank, title=f\"Masking\", aspect=\"equal\", xmax=18)\n",
    "# plt.imshow(fbank[0].cpu().numpy())\n",
    "fbank = fbank.squeeze(0)\n",
    "print(fbank.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from torchaudio.transforms import TimeStretch\n",
    "\n",
    "# 加载音频文件\n",
    "waveform, sample_rate = torchaudio.load(r'D:\\Shilong\\murmur\\03_circor_states\\Absent\\2530\\2530_AV.wav')\n",
    "# 转换为一维张量\n",
    "waveform = waveform[0, :]\n",
    "\n",
    "# 创建时间拉伸的变换器\n",
    "time_stretch = TimeStretch()\n",
    "\n",
    "# 设置拉伸因子\n",
    "stretch_factor = 1.5\n",
    "\n",
    "# 创建与波形数据样本数相匹配的拉伸因子张量\n",
    "num_samples = waveform.size(0)\n",
    "stretch_factor_tensor = torch.tensor([stretch_factor]).expand(num_samples)\n",
    "\n",
    "# 将拉伸因子转换为布尔值\n",
    "stretch_factor_tensor = stretch_factor_tensor.bool()\n",
    "\n",
    "# 进行时间拉伸\n",
    "stretched_waveform = time_stretch(waveform, stretch_factor_tensor)\n",
    "\n",
    "# 保存拉伸后的音频文件\n",
    "torchaudio.save('stretched_audio.wav', stretched_waveform, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "speed_factor=1.2\n",
    "time_path=r'D:\\Shilong\\murmur\\03_circor_states\\trainset\\volume2'\n",
    "path=r'D:\\Shilong\\murmur\\03_circor_states\\trainset\\present'\n",
    "for root,dir,file in os.walk(path):\n",
    "    for filename in file:\n",
    "        print(\"processing \"+filename)\n",
    "        wav_path=os.path.join(root,filename)\n",
    "        data, sr = librosa.load(wav_path, sr=None)\n",
    "        # data_time_stretch=librosa.effects.time_stretch(data, rate=speed_factor)\n",
    "        sf.write(os.path.join(time_path,filename+'_volume2.wav'),data,sr)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, AdamW\n",
    "\n",
    "# 定义设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加载预训练的BERT模型和tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 加载微调数据集\n",
    "train_dataset = YOUR_TRAIN_DATASET  # 替换为你自己的训练数据集\n",
    "val_dataset = YOUR_VALIDATION_DATASET  # 替换为你自己的验证数据集\n",
    "\n",
    "# 定义批处理大小和训练时的批处理器\n",
    "batch_size = 32\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 定义优化器和训练参数\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "num_epochs = 5\n",
    "\n",
    "# 将模型移动到设备上\n",
    "model.to(device)\n",
    "\n",
    "# 训练和微调过程\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in train_dataloader:\n",
    "        # 准备数据\n",
    "        inputs = tokenizer(batch['text'], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        labels = batch['label'].to(device)\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "        # 前向传播\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # 在验证集上进行评估\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            inputs = tokenizer(batch['text'], padding=True, truncation=True, return_tensors=\"pt\")\n",
    "            labels = batch['label'].to(device)\n",
    "            inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "            outputs = model(**inputs, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            predictions = torch.argmax(logits, dim=1)\n",
    "            correct_predictions += torch.sum(predictions == labels).item()\n",
    "            total_predictions += len(labels)\n",
    "\n",
    "    # 打印训练和验证信息\n",
    "    avg_train_loss = train_loss / len(train_dataloader)\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    val_accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "    print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
    "    print(f\"Val Loss: {avg_val_loss:.4f}\")\n",
    "    print(f\"Val Accuracy: {val_accuracy:.2%}\")\n",
    "\n",
    "# 保存微调后的模型\n",
    "model.save_pretrained(\"fine-tuned-model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 不同层对学习结果的贡献"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 梯度类别激活图（Grad-CAM）：\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# 加载预训练的模型\n",
    "model = models.resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# 图像预处理\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# 读取并预处理图像\n",
    "image = Image.open('image.jpg')\n",
    "input_tensor = preprocess(image)\n",
    "input_batch = input_tensor.unsqueeze(0)\n",
    "\n",
    "# 将输入图像转换为梯度可计算的形式\n",
    "input_batch.requires_grad_()\n",
    "\n",
    "# 前向传播\n",
    "output = model(input_batch)\n",
    "target_class = torch.argmax(output)\n",
    "\n",
    "# 反向传播计算梯度\n",
    "model.zero_grad()\n",
    "output[0, target_class].backward()\n",
    "\n",
    "# 获取目标层的梯度\n",
    "grads = model.get_activations_gradient()\n",
    "\n",
    "# 获取目标层的特征图\n",
    "target_activations = model.get_activations(input_batch).detach()\n",
    "\n",
    "# 计算类别激活图\n",
    "weights = torch.mean(grads, dim=(2, 3))[0]\n",
    "grad_cam = torch.sum(weights * target_activations, dim=1).relu()\n",
    "\n",
    "# 可视化类别激活图\n",
    "grad_cam = torch.nn.functional.interpolate(grad_cam.unsqueeze(0), size=(224, 224), mode='bilinear', align_corners=False)\n",
    "grad_cam = torch.nn.functional.normalize(grad_cam, dim=1)\n",
    "\n",
    "# 可以根据需要使用matplotlib等库进行可视化展示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import cv2\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from model_M7 import mobilenet_M7_large\n",
    "import json\n",
    "\n",
    "#导入预先训练好的网络\n",
    "model = mobilenet_M7_large(num_classes=4)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_weight_path = \"M7/best_M7.pth\"  #修改自己的权重文件\n",
    "model.load_state_dict(torch.load(model_weight_path))\n",
    "# model = torch.load(model_weight_path, map_location=device)\n",
    "model.eval()\n",
    "print(model) #可以注释掉\n",
    "\n",
    "#读取一张图片，对其可视化\n",
    "im = Image.open(\"test_image/0.jpg\")\n",
    "imarray = np.asarray(im) / 255.0\n",
    "# plt.figure()\n",
    "# plt.imshow(imarray)\n",
    "# plt.show()\n",
    "\n",
    "#数据预处理\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "input_im = data_transforms(im).unsqueeze(0)\n",
    "print(\"input_im.shape:\",input_im.shape)\n",
    "\n",
    "#定义辅助函数，获取指定层名称的特征，定义钩子hook\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model,input,output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "#获取中间卷积后的图像特征\n",
    "model.eval()\n",
    "#获取网络中第6层，经过第一次注意力后的特征映射，第一张特征图。\n",
    "model.features[6].register_forward_hook(get_activation(\"SqueezeExcitation\"))\n",
    "_ = model(input_im)\n",
    "SqueezeExcitation = activation[\"SqueezeExcitation\"]\n",
    "print(\"获取特征的尺寸为：\",SqueezeExcitation.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "for ii in range(SqueezeExcitation.shape[1]):\n",
    "    # 可视化每张手写体\n",
    "    plt.subplot(4, 10, ii + 1)\n",
    "    plt.imshow(SqueezeExcitation.data.numpy()[0, ii, :, :], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "plt.savefig(\"SqueezeExcitation6 map\")\n",
    "#获取更深层次的卷积后的图像特征\n",
    "model.eval()\n",
    "#获取网络中第14层，经过第二次注意力的特征映射，第二张特征图。\n",
    "model.features[14].register_forward_hook(get_activation(\"SqueezeExcitation\"))\n",
    "_ = model(input_im)\n",
    "SqueezeExcitation = activation[\"SqueezeExcitation\"]\n",
    "print(\"获取特征的尺寸为：\",SqueezeExcitation.shape)\n",
    "\n",
    "plt.figure(figsize=(10, 4))   \n",
    "for ii in range(40):\n",
    "    # 可视化每张手写体\n",
    "    plt.subplot(4, 10, ii + 1)\n",
    "    plt.imshow(SqueezeExcitation.data.numpy()[0, ii, :, :], cmap=\"gray\")\n",
    "    plt.axis(\"off\")\n",
    "plt.subplots_adjust(wspace=0.1, hspace=0.1)\n",
    "plt.savefig(\"SqueezeExcitation14 map\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function \n",
    "def train(num_epochs): \n",
    "    best_accuracy = 0.0 \n",
    "     \n",
    "    print(\"Begin training...\") \n",
    "    for epoch in range(1, num_epochs+1): \n",
    "        running_train_loss = 0.0 \n",
    "        running_accuracy = 0.0 \n",
    "        running_vall_loss = 0.0 \n",
    "        total = 0 \n",
    " \n",
    "        # Training Loop \n",
    "        for data in train_loader: \n",
    "        #for data in enumerate(train_loader, 0): \n",
    "            inputs, outputs = data  # get the input and real species as outputs; data is a list of [inputs, outputs] \n",
    "            optimizer.zero_grad()   # zero the parameter gradients          \n",
    "            predicted_outputs = model(inputs)   # predict output from the model \n",
    "            train_loss = loss_fn(predicted_outputs, outputs)   # calculate loss for the predicted output  \n",
    "            train_loss.backward()   # backpropagate the loss \n",
    "            optimizer.step()        # adjust parameters based on the calculated gradients \n",
    "            running_train_loss +=train_loss.item()  # track the loss value \n",
    " \n",
    "        # Calculate training loss value \n",
    "        train_loss_value = running_train_loss/len(train_loader) \n",
    " \n",
    "        # Validation Loop \n",
    "        with torch.no_grad(): \n",
    "            model.eval() \n",
    "            for data in validate_loader: \n",
    "                inputs, outputs = data \n",
    "                predicted_outputs = model(inputs) \n",
    "                val_loss = loss_fn(predicted_outputs, outputs) \n",
    "                \n",
    "                # The label with the highest value will be our prediction \n",
    "                _, predicted = torch.max(predicted_outputs, 1) \n",
    "                running_vall_loss += val_loss.item()  \n",
    "                total += outputs.size(0) \n",
    "                running_accuracy += (predicted == outputs).sum().item() \n",
    "\n",
    "        # Calculate validation loss value \n",
    "        val_loss_value = running_vall_loss/len(validate_loader) \n",
    "                \n",
    "        # Calculate accuracy as the number of correct predictions in the validation batch divided by the total number of predictions done.  \n",
    "        accuracy = (100 * running_accuracy / total)     \n",
    "\n",
    "        # Save the model if the accuracy is the best \n",
    "        if accuracy > best_accuracy: \n",
    "            saveModel() \n",
    "            best_accuracy = accuracy \n",
    "\n",
    "        # Print the statistics of the epoch \n",
    "        print('Completed training batch', epoch, 'Training Loss is: %.4f' %train_loss_value, 'Validation Loss is: %.4f' %val_loss_value, 'Accuracy is %d %%' % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "a=torch.tensor([10,10000])\n",
    "print(F.softmax(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \"\"\"my dataset.\"\"\"\n",
    "\n",
    "    # Initialize your data, download, etc.\n",
    "    def __init__(self, wavlabel, wavdata):\n",
    "        # 直接传递data和label\n",
    "        # self.len = wavlen\n",
    "        self.data = torch.from_numpy(wavdata)\n",
    "        self.label = torch.from_numpy(wavlabel)\n",
    "        self.id = torch.from_numpy(wavidx)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 根据索引返回数据和对应的标签\n",
    "        dataitem = torch.Tensor(self.data[index])\n",
    "        labelitem = torch.Tensor(self.label[index])\n",
    "        return dataitem.float(), labelitem.float()\n",
    "\n",
    "    def __len__(self):\n",
    "        # 返回文件数据的数目\n",
    "        return len(self.data)\n",
    "\n",
    "    def get_idx(self, index):\n",
    "        iditem = torch.Tensor(self.id[index])\n",
    "        return iditem\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多尺度熵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def sampEn(L:np.array, std : float ,m: int= 2, r: float = 0.15):\n",
    "    \"\"\" \n",
    "    计算时间序列的样本熵\n",
    "    \n",
    "    Input: \n",
    "        L: 时间序列\n",
    "        std: 原始序列的标准差\n",
    "        m: 1或2\n",
    "        r: 阈值\n",
    "        \n",
    "    Output: \n",
    "        SampEn\n",
    "    \"\"\"\n",
    "    N = len(L)\n",
    "    B = 0.0\n",
    "    A = 0.0\n",
    "\n",
    "    # Split time series and save all templates of length m\n",
    "    xmi = np.array([L[i:i+m] for i in range(N-m)])\n",
    "    xmj = np.array([L[i:i+m] for i in range(N-m+1)])\n",
    "    \n",
    "    # Save all matches minus the self-match, compute B\n",
    "    B = np.sum([np.sum(np.abs(xmii-xmj).max(axis=1) <= r * std)-1 for xmii in xmi])\n",
    "    # Similar for computing A\n",
    "    m += 1\n",
    "    xm = np.array([L[i:i+m] for i in range(N-m+1)])\n",
    "    \n",
    "    A = np.sum([np.sum(np.abs(xmi-xm).max(axis=1) <= r * std)-1 for xmi in xm])\n",
    "    # Return SampEn\n",
    "    return -np.log(A/B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import librosa\n",
    "# from SampEn import sampEn\n",
    "\n",
    "\n",
    "def MSE(signal , max_scale:int = 20):\n",
    "    result = []\n",
    "    length = len(signal)\n",
    "    std = np.std(signal)\n",
    "\n",
    "    for scale in range(1 , max_scale + 1):\n",
    "        # 确定截取的长度\n",
    "        length = int(len(signal) / scale) - 1\n",
    "        # 分段取平均\n",
    "        scale_i = signal[ : len(signal) : scale][:length]\n",
    "        for i in range(1,scale):\n",
    "            scale_i = scale_i + signal[i: len(signal) : scale][:length]\n",
    "        scale_i = scale_i / scale\n",
    "        #计算样本熵\n",
    "        result.append(sampEn(scale_i, std ,r = 0.15))\n",
    "        print(\"scale:\" , scale, 'SampEn' , result[-1])\n",
    "    return result\n",
    "\n",
    "\n",
    "# white_noise = pd.read_csv(\"white_noise.csv\").loc[:,'0']\n",
    "# white_noise = white_noise.to_numpy()\n",
    "\n",
    "data,_=librosa.load(r'C:\\Users\\lsl198\\Desktop\\倒放.wav', sr=4000)\n",
    "begin = time.time()\n",
    "entropy = MSE(data , 20)\n",
    "end = time.time()\n",
    "\n",
    "print(\"用时：\" , int((end - begin)/60) ,'min', (end - begin) % 60 , 's')\n",
    "print(entropy)\n",
    "\n",
    "plt.plot(entropy)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "a=[1,2,3]\n",
    "b=['a','b','c']\n",
    "pd.DataFrame(zip(a,b)).to_csv(\n",
    "    \"absent_train_dic.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 每一段进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def segment_classifier(result_list_1=[]):\n",
    "    npy_path_padded = r\"D:\\Shilong\\murmur\\01_dataset\\01_s1s2\\npyFile_padded\\normalized\\list_npy_files\"\n",
    "    absent_test_index = np.load(\n",
    "        npy_path_padded + r\"\\absent_test_index_norm.npy\", allow_pickle=True\n",
    "    )\n",
    "    present_test_index = np.load(\n",
    "        npy_path_padded + r\"\\present_test_index_norm.npy\", allow_pickle=True\n",
    "    )\n",
    "    absent_test_names = np.load(\n",
    "        npy_path_padded + r\"\\absent_test_names_norm.npy\", allow_pickle=True\n",
    "    )\n",
    "    present_test_names = np.load(\n",
    "        npy_path_padded + r\"\\present_test_names_norm.npy\", allow_pickle=True\n",
    "    )\n",
    "    absent_test_dic = dict(zip(absent_test_names,absent_test_index, ))\n",
    "    present_test_dic = dict(zip(present_test_names,present_test_index, ))\n",
    "    # 所有测试数据的字典\n",
    "    test_dic={**absent_test_dic,**present_test_dic}\n",
    "    #创建id_pos:idx的字典 \n",
    "    id_idx_dic={} \n",
    "    # 遍历test_dic，生成id_pos:idx的字典\n",
    "    for file_name,data_index in test_dic.items():\n",
    "        id_pos=file_name.split('_')[0]+'_'+file_name.split('_')[1]\n",
    "        if not id_pos in id_idx_dic.keys():#如果id_pos不在字典中，就创建一个新的键值对\n",
    "            id_idx_dic[id_pos]=[data_index]\n",
    "        else: # 如果id_pos在字典中，就把value添加到对应的键值对的值中\n",
    "            id_idx_dic[id_pos].append(data_index)\n",
    "\n",
    "    # 这里result_list_1列表，用来存储分类结果为1对应的id\n",
    "    # 创建一个空字典，用来存储分类结果\n",
    "    result_dic={}\n",
    "    # 这样就生成了每个听诊区对应的数据索引，然后就可以根据索引读取数据了\n",
    "    for id_pos,data_index in id_idx_dic.items():\n",
    "        # 创建空列表用于保存数据索引对应的值\n",
    "        value_list=[]\n",
    "        # 遍历这个id_pos对应的所有数据索引\n",
    "        for idx in data_index:\n",
    "            # 根据索引读取数据\n",
    "            if idx in result_list_1:\n",
    "                value_list.append(1)\n",
    "            else:\n",
    "                value_list.append(0)\n",
    "        # 计算平均值作为每一段的最终分类结果，大于0.5就是1，小于0.5就是0\n",
    "        result_dic[id_pos]=value_list.mean()\n",
    "    return result_dic\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 按照患者分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "id_idx_dic={}\n",
    "id_pos=11\n",
    "id_idx_dic[id_pos]=['aa']\n",
    "id_idx_dic[id_pos].append('bb')\n",
    "\n",
    "print(id_idx_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def csv_reader_cl(file_name, clo_num):\n",
    "    with open(file_name, encoding=\"utf-8\") as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        column = [row[clo_num] for row in reader]\n",
    "    return column\n",
    "def csv_reader_row(file_name, row_num):\n",
    "    with open(file_name, \"r\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        row = list(reader)\n",
    "    return row[row_num]\n",
    "absent_test_id_path = r\"D:\\Shilong\\murmur\\03_circor_states\\absent_test_id.csv\"\n",
    "present_test_id_path = r\"D:\\Shilong\\murmur\\03_circor_states\\present_test_id.csv\"\n",
    "csv_path = r\"D:\\Shilong\\murmur\\dataset_all\\training_data.csv\"\n",
    "\n",
    "# get dataset tag from table\n",
    "row_line = csv_reader_row(csv_path, 0)\n",
    "tag_list = []\n",
    "\n",
    "# get index for 'Patient ID' and 'Outcome'\n",
    "tag_list.append(row_line.index(\"Patient ID\"))\n",
    "tag_list.append(row_line.index(\"Murmur\"))\n",
    "tag_list.append(row_line.index(\"Recording locations:\"))\n",
    "\n",
    "absent_test_id = csv_reader_cl(absent_test_id_path, 0)\n",
    "present_test_id = csv_reader_cl(present_test_id_path, 0)\n",
    "id_data = csv_reader_cl(csv_path, tag_list[0])\n",
    "Murmur = csv_reader_cl(csv_path, tag_list[1])\n",
    "Recording_locations = csv_reader_cl(csv_path, tag_list[2])\n",
    "# 所有测试数据的id\n",
    "test_id = absent_test_id+present_test_id\n",
    "patient_target=[]\n",
    "patient_dic={}\n",
    "# print(absent_test_id)\n",
    "for id in test_id:\n",
    "    murmur=Murmur[id_data.index(id)]\n",
    "    if murmur=='present':\n",
    "        patient_target.append(1)\n",
    "    else:\n",
    "        patient_target.append(0)\n",
    "    locations=Recording_locations[id_data.index(id)]\n",
    "    patient_dic[id]=locations\n",
    "\n",
    "# result_dic用来存储分类结果,formate: id_pos: result\n",
    "result_dic={}\n",
    "# patient_result_dic用于保存每个患者每个听诊区的分类结果，formate: id: location1_result,location2_result\n",
    "patient_result_dic={}\n",
    "print(patient_dic)\n",
    "for patient_id,locations in patient_dic.items():\n",
    "    for location in locations.split('+'):\n",
    "        id_loc=patient_id+'_'+location\n",
    "        if  id_loc in result_dic.keys():\n",
    "            if not patient_id in patient_result_dic.keys():\n",
    "                patient_result_dic[patient_id]=result_dic[id_loc]\n",
    "            else:\n",
    "                patient_result_dic[patient_id]+=result_dic[id_loc]\n",
    "        else:\n",
    "            print('[waring]: '+id_loc+' not in result_dic')\n",
    "\n",
    "# 遍历patient_result_dic，计算每个患者的最终分类结果\n",
    "patient_output_dic={}\n",
    "patient_output=[]\n",
    "patient_target=[]\n",
    "for patient_id,result in patient_result_dic.items():\n",
    "    # 做output\n",
    "    if np.mean(result)==0:\n",
    "        patient_output_dic[patient_id]=0\n",
    "        patient_output.append(0)\n",
    "    else:\n",
    "        patient_output_dic[patient_id]=1\n",
    "        patient_output.append(1)\n",
    "    # 做target\n",
    "    if patient_id in absent_test_id:\n",
    "        patient_target.append(0)\n",
    "    elif patient_target in present_test_id:\n",
    "        patient_target.append(1)\n",
    "    else:\n",
    "        print('[waring]: '+patient_id+' not in test_id')\n",
    "        \n",
    "# 计算准确率和混淆矩阵\n",
    "# 计算准确率\n",
    "patient_acc = (np.array(patient_output) == np.array(\n",
    "    patient_target)).sum()/len(patient_target)\n",
    "# 计算混淆矩阵\n",
    "patient_cm = confusion_matrix(patient_target, patient_output)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## patient分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from util.BEATs_def import draw_confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "def draw_confusion_matrix(\n",
    "    cm,\n",
    "    label_name,\n",
    "    title=\"Confusion Matrix\",\n",
    "    pdf_save_path=None,\n",
    "    dpi=600,\n",
    "    epoch=0,\n",
    "):\n",
    "    \"\"\"\n",
    "\n",
    "    @param label_true: 真实标签，比如[0,1,2,7,4,5,...]\n",
    "    @param label_pred: 预测标签，比如[0,5,4,2,1,4,...]\n",
    "    @param label_name: 标签名字，比如['cat','dog','flower',...]\n",
    "    @param normlize: 是否设元素为百分比形式\n",
    "    @param title: 图标题\n",
    "    @param pdf_save_path: 是否保存，是则为保存路径pdf_save_path=xxx.png | xxx.pdf | ...等其他plt.savefig支持的保存格式\n",
    "    @param dpi: 保存到文件的分辨率，论文一般要求至少300dpi\n",
    "    @return:\n",
    "\n",
    "    example：\n",
    "            draw_confusion_matrix(label_true=y_gt,\n",
    "                          label_pred=y_pred,\n",
    "                          label_name=[\"Angry\", \"Disgust\", \"Fear\", \"Happy\", \"Sad\", \"Surprise\", \"Neutral\"],\n",
    "                          normlize=True,\n",
    "                          title=\"Confusion Matrix on Fer2013\",\n",
    "                          pdf_save_path=\"Confusion_Matrix_on_Fer2013.png\",\n",
    "                          dpi=300)\n",
    "\n",
    "    \"\"\"\n",
    "    row_sums = np.sum(cm, axis=1)  # 计算每行的和\n",
    "    cm = cm.T\n",
    "    plt.imshow(cm.T, cmap=\"Greens\")\n",
    "    # plt.title(title)\n",
    "    plt.xlabel(\"Predict label\")\n",
    "    plt.ylabel(\"Truth label\")\n",
    "    plt.yticks(range(label_name.__len__()), label_name)\n",
    "    plt.xticks(range(label_name.__len__()), label_name)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.colorbar()\n",
    "\n",
    "    for i in range(label_name.__len__()):\n",
    "        for j in range(label_name.__len__()):\n",
    "            # color = (1, 1, 1) if i == j else (0, 0, 0)  # 对角线字体白色，其他黑色\n",
    "            # value = float(format(\"%.4f\" % cm[i, j]))\n",
    "            str_value = \"{}\".format(cm[i, j])\n",
    "            plt.text(\n",
    "                i,\n",
    "                j,\n",
    "                str_value,\n",
    "                verticalalignment=\"center\",\n",
    "                horizontalalignment=\"center\",\n",
    "                # color=color,\n",
    "            )\n",
    "\n",
    "    # plt.show()\n",
    "    if not pdf_save_path is None:\n",
    "        if not os.path.exists(pdf_save_path):\n",
    "            os.makedirs(pdf_save_path)\n",
    "        plt.savefig(\n",
    "            pdf_save_path + \"/epoch\" + str(epoch) + \".png\",\n",
    "            bbox_inches=\"tight\",\n",
    "            dpi=dpi,\n",
    "        )\n",
    "        plt.close()\n",
    "\n",
    "patient_cm=np.array([[136,3], [ 5,31]])\n",
    "draw_confusion_matrix(\n",
    "            patient_cm,\n",
    "            [\"Absent\", \"Present\"],\n",
    "            \"epoch428 testacc:95.429%\",\n",
    "            pdf_save_path = r\"./location_cm/\" +str(datetime.now().strftime(\"%Y-%m%d %H%M\")),\n",
    "            epoch = 428\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "data=[0.2 0.1]\n",
    "\n",
    "# data=(data-np.mean(data))/(np.max(data)-np.min(data))\n",
    "# data\n",
    "data=np.array(data).reshape(-1,1)\n",
    "# data=data-np.mean(data)\n",
    "data = preprocessing.MinMaxScaler((-1,1)).fit_transform(data)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "a=[]\n",
    "for i in range(-5,5):\n",
    "    b=[]\n",
    "    b.append(i)\n",
    "    a.append(b)\n",
    "\n",
    "# #print(a)   \n",
    "l=np.array(a)\n",
    "print('l=',l)\n",
    "x = preprocessing.MaxAbsScaler().fit_transform(l)\n",
    "print('x=',x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [7, 13, 14, 3],\n",
       " 1: [1, 11, 17, 16],\n",
       " 2: [4, 0, 12, 9],\n",
       " 3: [5, 18, 2, 15],\n",
       " 4: [8, 10, 6]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 五折\n",
    "import numpy as np\n",
    "import random\n",
    "data_absnet =list(range(19))\n",
    "random.shuffle(data)\n",
    "flod5_absent={}\n",
    "for i in range(5):\n",
    "    if i not in flod5_absent:\n",
    "        flod5_absent[i] = []\n",
    "    flod5_absent[i].extend(data[i*4:i*4+4])\n",
    "flod5_absent\n",
    "# present\n",
    "data_absnet =list(range(19))\n",
    "random.shuffle(data)\n",
    "flod5_absent={}\n",
    "flod5_absent[i] = []\n",
    "flod5_absent[i].extend(data[i*4:i*4+4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始序列SIZE:694\n",
      "第0折:size:139, value:[423, 229, 639, 521, 561, 178, 581, 136, 654, 458, 225, 438, 636, 145, 643, 304, 512, 81, 629, 678, 246, 434, 269, 590, 281, 50, 531, 47, 623, 190, 96, 399, 652, 383, 152, 447, 632, 464, 212, 201, 477, 511, 392, 545, 230, 336, 608, 621, 57, 550, 567, 622, 486, 565, 150, 358, 460, 137, 200, 612, 498, 223, 315, 17, 86, 657, 185, 240, 48, 22, 658, 469, 670, 508, 268, 119, 271, 60, 23, 497, 578, 182, 640, 37, 490, 328, 161, 467, 348, 356, 210, 89, 105, 505, 65, 628, 386, 425, 135, 292, 474, 245, 441, 687, 11, 601, 359, 407, 41, 448, 382, 593, 525, 49, 553, 32, 156, 502, 38, 507, 384, 197, 676, 54, 648, 307, 297, 582, 27, 99, 345, 562, 134, 592, 352, 158, 75, 334, 324] \n",
      "第1折:size:139, value:[333, 258, 30, 579, 179, 584, 580, 530, 568, 247, 9, 646, 299, 3, 129, 679, 396, 689, 391, 28, 516, 395, 394, 404, 457, 2, 471, 233, 342, 548, 351, 595, 625, 326, 473, 416, 309, 556, 277, 594, 52, 357, 500, 250, 120, 535, 390, 666, 172, 78, 77, 264, 238, 67, 476, 373, 224, 261, 408, 575, 536, 323, 117, 387, 85, 133, 243, 488, 108, 633, 677, 279, 576, 683, 284, 175, 241, 528, 421, 572, 656, 31, 231, 406, 140, 514, 355, 123, 372, 526, 234, 169, 481, 468, 617, 442, 409, 195, 524, 517, 542, 440, 272, 6, 603, 320, 149, 267, 254, 570, 7, 188, 62, 347, 300, 127, 262, 162, 367, 519, 130, 426, 626, 142, 237, 449, 265, 484, 25, 653, 668, 419, 257, 198, 183, 306, 509, 21, 263] \n",
      "第2折:size:139, value:[661, 577, 369, 174, 624, 51, 194, 388, 205, 244, 563, 389, 214, 412, 532, 596, 276, 213, 503, 222, 534, 101, 33, 36, 614, 125, 112, 144, 485, 69, 221, 288, 115, 610, 495, 691, 496, 138, 462, 365, 620, 160, 615, 587, 301, 103, 12, 456, 283, 26, 291, 114, 541, 630, 651, 141, 24, 68, 559, 302, 202, 56, 255, 465, 432, 61, 5, 443, 380, 337, 660, 59, 90, 422, 126, 450, 148, 116, 506, 219, 94, 540, 415, 341, 551, 455, 180, 451, 564, 204, 34, 228, 170, 330, 107, 20, 655, 371, 232, 607, 665, 235, 688, 437, 139, 66, 472, 522, 106, 681, 649, 100, 605, 445, 446, 647, 344, 208, 285, 377, 329, 266, 619, 398, 675, 15, 124, 102, 164, 436, 435, 664, 310, 627, 128, 487, 673, 168, 598] \n",
      "第3折:size:139, value:[298, 64, 588, 0, 313, 248, 491, 19, 433, 613, 338, 340, 499, 368, 18, 659, 604, 504, 600, 418, 260, 374, 91, 482, 452, 381, 546, 166, 193, 251, 71, 685, 690, 363, 631, 510, 692, 217, 533, 159, 176, 84, 686, 280, 378, 294, 385, 82, 42, 287, 429, 70, 427, 327, 121, 583, 350, 544, 45, 364, 10, 132, 14, 667, 606, 181, 206, 74, 325, 16, 634, 680, 430, 218, 249, 645, 370, 318, 8, 461, 203, 635, 618, 215, 322, 98, 411, 410, 555, 475, 552, 420, 641, 585, 402, 211, 493, 242, 83, 527, 189, 642, 312, 239, 574, 353, 227, 554, 478, 111, 354, 589, 146, 543, 273, 173, 295, 311, 286, 539, 39, 76, 693, 72, 296, 220, 155, 376, 537, 209, 191, 650, 644, 73, 13, 682, 314, 566, 401] \n",
      "第4折:size:138, value:[252, 207, 549, 366, 53, 638, 275, 571, 167, 63, 321, 669, 400, 95, 538, 454, 518, 92, 339, 87, 43, 413, 453, 569, 319, 520, 403, 684, 154, 171, 187, 110, 256, 397, 29, 259, 494, 361, 405, 226, 439, 349, 379, 611, 513, 424, 184, 602, 1, 431, 293, 480, 463, 44, 597, 470, 616, 393, 79, 118, 459, 303, 131, 492, 305, 332, 414, 479, 489, 663, 147, 335, 672, 317, 662, 143, 192, 40, 270, 165, 55, 466, 157, 560, 362, 637, 547, 501, 113, 599, 282, 444, 216, 88, 153, 278, 58, 186, 151, 591, 375, 483, 331, 609, 163, 671, 523, 109, 35, 346, 417, 97, 586, 308, 428, 674, 46, 316, 177, 196, 253, 93, 573, 236, 199, 515, 558, 122, 557, 80, 343, 290, 4, 104, 360, 289, 529, 274] \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def flod_devide(data,flod_num=5):\n",
    "    # 打乱序列\n",
    "    random.shuffle(data)\n",
    "    # 五折\n",
    "    flod5={}\n",
    "    point=[]\n",
    "    for i in range(flod_num):\n",
    "        point.append(i*round(len(data)/flod_num))\n",
    "    # print(point)\n",
    "    # 分割序列 \n",
    "    for i in range(len(point)):\n",
    "        if i<len(point)-1:    \n",
    "            flod5[i] = []\n",
    "            flod5[i].extend(data[point[i]:point[i+1]])\n",
    "        else:\n",
    "            flod5[i] = []\n",
    "            flod5[i].extend(data[point[-1]:])\n",
    "    return flod5\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "\n",
    "    # # 定义原始序列\n",
    "    sequence = list(range(0,694))\n",
    "    print(\"原始序列SIZE:\"+str(len(sequence)))\n",
    "    flod5=flod_devide(sequence,5)\n",
    "    # # 打乱序列\n",
    "    # random.shuffle(sequence)\n",
    "    # print(\"打乱后的序列:\", sequence)\n",
    "\n",
    "    # # 五折\n",
    "    # flod_num=5\n",
    "    # # present\n",
    "    # point=[]\n",
    "    # for i in range(flod_num):\n",
    "    #     point.append(i*round(len(sequence)/flod_num))\n",
    "    # # print(point)\n",
    "    # flod5={}\n",
    "    # # 分割序列 \n",
    "    # for i in range(len(point)):\n",
    "    #     if i<len(point)-1:    \n",
    "    #         flod5[i] = []\n",
    "    #         flod5[i].extend(sequence[point[i]:point[i+1]])\n",
    "    #     else:\n",
    "    #         flod5[i] = []\n",
    "    #         flod5[i].extend(sequence[point[-1]:])\n",
    "    # print(\"分割后的序列:\")\n",
    "    for k,v in flod5.items():\n",
    "        print(\"第{}折:size:{}, value:{} \".format(k,len(v),v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_0\n",
      "['absent', 'present', 'reverse0.8', 'reverse0.9', 'reverse1.0', 'reverse1.1', 'reverse1.2', 'time_stretch0.8', 'time_stretch0.9', 'time_stretch1.1', 'time_stretch1.2']\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_0\\absent\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_0\\present\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_0\\reverse0.8\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_0\\reverse0.9\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_0\\reverse1.0\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_0\\reverse1.1\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_0\\reverse1.2\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_0\\time_stretch0.8\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_0\\time_stretch0.9\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_0\\time_stretch1.1\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_0\\time_stretch1.2\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_1\n",
      "['absent', 'present', 'reverse0.8', 'reverse0.9', 'reverse1.0', 'reverse1.1', 'reverse1.2', 'time_stretch0.8', 'time_stretch0.9', 'time_stretch1.1', 'time_stretch1.2']\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_1\\absent\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_1\\present\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_1\\reverse0.8\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_1\\reverse0.9\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_1\\reverse1.0\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_1\\reverse1.1\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_1\\reverse1.2\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_1\\time_stretch0.8\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_1\\time_stretch0.9\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_1\\time_stretch1.1\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_1\\time_stretch1.2\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_2\n",
      "['absent', 'present', 'reverse0.8', 'reverse0.9', 'reverse1.0', 'reverse1.1', 'reverse1.2', 'time_stretch0.8', 'time_stretch0.9', 'time_stretch1.1', 'time_stretch1.2']\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_2\\absent\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_2\\present\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_2\\reverse0.8\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_2\\reverse0.9\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_2\\reverse1.0\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_2\\reverse1.1\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_2\\reverse1.2\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_2\\time_stretch0.8\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_2\\time_stretch0.9\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_2\\time_stretch1.1\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_2\\time_stretch1.2\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_3\n",
      "['absent', 'present', 'reverse0.8', 'reverse0.9', 'reverse1.0', 'reverse1.1', 'reverse1.2', 'time_stretch0.8', 'time_stretch0.9', 'time_stretch1.1', 'time_stretch1.2']\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_3\\absent\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_3\\present\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_3\\reverse0.8\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_3\\reverse0.9\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_3\\reverse1.0\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_3\\reverse1.1\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_3\\reverse1.2\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_3\\time_stretch0.8\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_3\\time_stretch0.9\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_3\\time_stretch1.1\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_3\\time_stretch1.2\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_4\n",
      "['absent', 'present', 'reverse0.8', 'reverse0.9', 'reverse1.0', 'reverse1.1', 'reverse1.2', 'time_stretch0.8', 'time_stretch0.9', 'time_stretch1.1', 'time_stretch1.2']\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_4\\absent\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_4\\present\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_4\\reverse0.8\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_4\\reverse0.9\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_4\\reverse1.0\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_4\\reverse1.1\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_4\\reverse1.2\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_4\\time_stretch0.8\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_4\\time_stretch0.9\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_4\\time_stretch1.1\n",
      "D:\\Shilong\\murmur\\01_dataset\\05_5fold\\fold_set_4\\time_stretch1.2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "root_path = r\"D:\\Shilong\\murmur\\01_dataset\\05_5fold\"\n",
    "for k in range(5):    \n",
    "    src_fold_root_path = root_path+r\"\\fold_set_\"+str(k)\n",
    "    print(src_fold_root_path)\n",
    "    a=os.listdir(src_fold_root_path)\n",
    "    print(a)\n",
    "    # for name in a:\n",
    "    #     print(src_fold_root_path+'\\\\'+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['14241_AV', '14241_MV', '14241_PV', '14241_TV', '44514_AV', '44514_MV', '44514_PV', '44514_TV', '46579_AV', '46579_MV', '46579_PV', '46579_TV', '49572_MV', '49572_PV', '49572_TV', '49691_AV', '49691_MV', '49691_PV', '49691_TV', '49748_MV', '49748_TV', '49850_AV', '49850_MV', '50056_AV', '50056_MV', '50056_PV', '50056_TV', '50099_MV', '50099_PV', '50099_TV', '50129_AV', '50129_MV', '50129_PV', '50129_TV', '50161_MV', '50161_PV', '50161_TV', '50229_AV', '50229_MV', '50229_PV', '50229_TV', '50285_MV', '50289_AV', '50289_MV', '50289_PV', '50289_TV', '50746_AV', '50746_MV', '50746_PV', '50746_TV', '51064_MV', '57700_MV', '57700_PV', '57700_TV', '68204_AV', '68204_MV', '68204_PV', '68204_TV', '68379_AV', '68379_MV', '68379_PV', '68379_TV', '68487_AV', '68487_MV', '68487_PV', '68487_TV', '69120_AV', '69120_MV', '69120_PV', '69120_TV', '83094_MV', '84692_AV', '84692_MV', '84692_PV', '84692_TV', '84695_AV', '84695_MV', '84695_PV', '84695_TV', '84714_AV', '84714_MV', '84714_TV', '84732_AV', '84732_MV', '84751_AV', '84751_MV', '84751_PV', '84751_TV', '84854_AV', '84854_MV', '84854_PV', '84854_TV', '84896_AV', '84896_MV', '84896_PV', '84896_TV', '85002_AV', '85002_MV', '85002_PV', '85002_TV', '85165_AV', '85165_MV', '85207_AV', '85207_MV', '85207_PV', '85207_TV', '85243_AV', '85243_PV', '85259_AV', '85259_MV', '85261_AV', '85261_MV', '85261_PV', '85261_TV', '85306_AV', '85306_MV']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "path_a=r'D:\\Shilong\\murmur\\01_dataset\\01_s1s2\\test\\Present'\n",
    "absent_id_path = r'D:\\Shilong\\murmur\\01_dataset\\01_s1s2\\Present_test_id.csv'\n",
    "a = os.listdir(path_a)\n",
    "print(a)\n",
    "absent_test_id=[]\n",
    "for name in a:\n",
    "    segs=name.split('_')[0]\n",
    "    if segs not in absent_test_id:\n",
    "        absent_test_id.append(segs)\n",
    "pd.DataFrame(data=absent_test_id, index=None).to_csv(\n",
    "    absent_id_path, index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.5\n",
      "[0.53939394 0.47878788 0.41818182 0.         0.6        0.66060606\n",
      " 0.72121212 0.78181818 0.84242424 0.9030303  1.        ]\n",
      "16.5\n",
      "[0.53939394 0.47878788 0.41818182 0.         0.         0.06060606\n",
      " 0.12121212 0.18181818 0.24242424 0.3030303  0.4       ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def wav_normalize(data):\n",
    "    \"\"\"归一化\"\"\"\n",
    "    range = np.max(data) - np.min(data)\n",
    "    data = (data-np.min(data))/range\n",
    "    print(range)\n",
    "    return data\n",
    "\n",
    "\n",
    "def wav_normalize_new(data):\n",
    "    rang = np.max(data) - np.min(data)\n",
    "    print(rang)\n",
    "    for i in range(data.shape[0]):\n",
    "        data[i] = (data[i] - np.min(data)) / rang\n",
    "    return data\n",
    "\n",
    "a=np.array([-1,-2,-3,-9.9,0.0,1.0,2.0,3.0,4.0,5.0,6.6])\n",
    "\n",
    "print(wav_normalize(a))\n",
    "print(wav_normalize_new(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7102)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torcheval.metrics.functional import binary_auprc, binary_auroc, binary_f1_score, binary_confusion_matrix, binary_accuracy, binary_precision, binary_recall\n",
    "input = torch.tensor([0,0,0,1,1,1,1,1,1,1])\n",
    "target = torch.tensor([1, 0, 1, 1,0,0,1,1,1,1])\n",
    "binary_confusion_matrix(input, target, normalize='none')\n",
    "binary_auprc(input, target )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 提特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Lubdub\n",
    "def getSpringerPCGFeatures(despiked_data, Fs, audio_segmentation_Fs=50, figures=False):\n",
    "\n",
    "    ########## Homomorphic envelope ##########\n",
    "\n",
    "    # Find the homomorphic envelope\n",
    "    homomorphic_envelope = Homomorphic_Envelope_with_Hilbert(despiked_data, Fs)\n",
    "    # plt.plot(homomorphic_envelope)\n",
    "    # Downsample the envelope:\n",
    "    num_samps = round(np.size(homomorphic_envelope)/Fs*audio_segmentation_Fs)\n",
    "    downsampled_homomorphic_envelope = signal.resample(\n",
    "        homomorphic_envelope, num_samps)\n",
    "    # normalise the envelope:\n",
    "    downsampled_homomorphic_envelope = normalize_signal(\n",
    "        downsampled_homomorphic_envelope)\n",
    "    # plt.plot(downsampled_homomorphic_envelope)\n",
    "    ########## Hilbert Envelope ##########\n",
    "    # Hilbert Envelope\n",
    "    hilbert_envelope = Hilbert_Envelope(despiked_data, Fs, figures=0)\n",
    "    downsampled_hilbert_envelope = signal.resample(hilbert_envelope, num_samps)\n",
    "    downsampled_hilbert_envelope = normalize_signal(\n",
    "        downsampled_hilbert_envelope)\n",
    "    ########## Get power spectral density features ##########\n",
    "    psd = get_PSD_feature_Springer_HMM(despiked_data, Fs, 40, 60)\n",
    "    psd = signal.resample_poly(\n",
    "        psd, len(downsampled_homomorphic_envelope), len(psd))\n",
    "    psd = normalize_signal(psd)\n",
    "    ########## Wavelet features ##########\n",
    "    # if include_wavelet_features:\n",
    "    wavelet_level = 3\n",
    "    wavelet_name = 'db7'\n",
    "    [cA, cD, _, _] = pywt.wavedec(\n",
    "        despiked_data, wavelet_name, mode='zero', level=wavelet_level)\n",
    "    wavelet_feature = signal.resample_poly(\n",
    "        abs(cD), len(downsampled_homomorphic_envelope), len(cD))\n",
    "    wavelet_feature = normalize_signal(wavelet_feature)\n",
    "    ########## Wavelet features ##########\n",
    "    # if include_wavelet_features:\n",
    "    PCG_Features = [downsampled_homomorphic_envelope,\n",
    "                    downsampled_hilbert_envelope, psd, wavelet_feature]\n",
    "\n",
    "    return PCG_Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gamatong特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'dot'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Shilong\\murmur\\00_Code\\LM\\beats1\\BEATs\\BEATs_try.ipynb 单元格 77\u001b[0m line \u001b[0;36m9\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Shilong/murmur/00_Code/LM/beats1/BEATs/BEATs_try.ipynb#Y136sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m y\u001b[39m=\u001b[39mlibrosa\u001b[39m.\u001b[39mutil\u001b[39m.\u001b[39mnormalize(y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Shilong/murmur/00_Code/LM/beats1/BEATs/BEATs_try.ipynb#Y136sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m magnitude \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabs(librosa\u001b[39m.\u001b[39mstft(y,win_length\u001b[39m=\u001b[39m\u001b[39m512\u001b[39m))\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Shilong/murmur/00_Code/LM/beats1/BEATs/BEATs_try.ipynb#Y136sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m Gam\u001b[39m=\u001b[39mgammatone_filter_bank\u001b[39m.\u001b[39;49mdot(magnitude)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Shilong/murmur/00_Code/LM/beats1/BEATs/BEATs_try.ipynb#Y136sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m LogGamSpec \u001b[39m=\u001b[39m librosa\u001b[39m.\u001b[39mpower_to_db(Gam,ref\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mmax)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'dot'"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from spafe.fbanks.gammatone_fbanks import gammatone_filter_banks\n",
    "File_name = r'D:\\Shilong\\murmur\\01_dataset\\07_newnorm\\Present\\9979\\9979_AV.wav'\n",
    "y,sr=librosa.load(File_name,sr=4000)\n",
    "gammatone_filter_bank = gammatone_filter_banks(nfilts=64, nfft=512, fs=sr, low_freq=100, high_freq=None,  order=4)\n",
    "y=librosa.util.normalize(y)\n",
    "magnitude = np.abs(librosa.stft(y,win_length=512))**2\n",
    "Gam=gammatone_filter_bank.dot(magnitude)\n",
    "LogGamSpec = librosa.power_to_db(Gam,ref=np.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# from patient_information import get_height, get_weight, load_patient_data, get_pregnancy_status, get_age, compare_strings, get_sex\n",
    "import numpy as np\n",
    "import librosa\n",
    "import warnings\n",
    "from scipy import signal\n",
    "# from python_speech_features import logfbank\n",
    "from spafe.features.gfcc import erb_spectrogram\n",
    "from spafe.utils.preprocessing import SlidingWindow\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def Log_GF(data_directory):\n",
    "    x, fs = librosa.load(os.path.join(data_directory, f), sr=4000)\n",
    "    # energy = Energy(x,fs,100,50)\n",
    "    gSpec, gfreqs = erb_spectrogram(x,fs=fs,pre_emph=0,pre_emph_coeff=0.97,window=SlidingWindow(0.025, 0.0125, \"hamming\"),nfilts=64,nfft=512,low_freq=25,high_freq=2000)\n",
    "    fbank_feat = gSpec.T\n",
    "    # fbank_feat = fbank_feat*energy\n",
    "    fbank_feat = np.log(fbank_feat)\n",
    "    fbank_feat = (fbank_feat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6831)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "p = torch.tensor([0.2057, 0.8667, 1.0000])\n",
    "r = torch.tensor([1.0000, 0.7222, 0.0000])\n",
    "# p[0]*r[0]+p[1]*r[1]-p[0]*r[1]\n",
    "-torch.sum((r[1:] -r[:-1])*p[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'root_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Shilong\\murmur\\00_Code\\LM\\beats1\\BEATs\\BEATs_try.ipynb 单元格 80\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Shilong/murmur/00_Code/LM/beats1/BEATs/BEATs_try.ipynb#Y143sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmake_dataset\u001b[39;00m \u001b[39mimport\u001b[39;00m get_features_mod\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Shilong/murmur/00_Code/LM/beats1/BEATs/BEATs_try.ipynb#Y143sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m##\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Shilong/murmur/00_Code/LM/beats1/BEATs/BEATs_try.ipynb#Y143sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m txtpath \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mD:\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mShilong\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mmurmur\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mPCGdataset\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mtraining_data\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m2530.txt\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[1;32md:\\Shilong\\murmur\\00_Code\\LM\\beats1\\BEATs\\util\\make_dataset.py:578\u001b[0m\n\u001b[0;32m    575\u001b[0m         \u001b[39mfor\u001b[39;00m murmur \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mabsent\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpresent\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m    576\u001b[0m             src_fold_path \u001b[39m=\u001b[39m src_fold_root_path\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mmurmur\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\\\\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m--> 578\u001b[0m data_set(root_path)\n\u001b[0;32m    581\u001b[0m \u001b[39m# # 复制到trainset和testset\u001b[39;00m\n\u001b[0;32m    582\u001b[0m \u001b[39m# # trainset\u001b[39;00m\n\u001b[0;32m    583\u001b[0m \u001b[39m# 将训练集和测试集文件分别copy到train和test文件夹\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    601\u001b[0m \u001b[39m#         if state == 'Present':\u001b[39;00m\n\u001b[0;32m    602\u001b[0m \u001b[39m#             shutil.copy(files, target_dir_test_p + \"\\\\\")\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'root_path' is not defined"
     ]
    }
   ],
   "source": [
    "from util.make_dataset import get_features_mod\n",
    "\n",
    "##\n",
    "txtpath = r\"D:\\Shilong\\murmur\\Dataset\\PCGdataset\\training_data\\2530.txt\"\n",
    "get_features_mod(txtpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_Shilong",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
